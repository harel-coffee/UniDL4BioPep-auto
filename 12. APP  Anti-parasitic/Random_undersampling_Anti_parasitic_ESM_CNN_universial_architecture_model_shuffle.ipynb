{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### requirements for the following codings\n"
   ],
   "metadata": {
    "id": "95NTckuFZZzm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### packages required \n",
    "# !pip install fair-esm \n",
    "# !pip install torch\n",
    "# !pip install tensorflow\n",
    "# !pip install sklearn"
   ],
   "metadata": {
    "id": "UO71IBS6ZgZV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "50173292-3e7b-4393-959b-a8712004aa5d",
    "ExecuteTime": {
     "end_time": "2024-07-12T21:45:02.017828Z",
     "start_time": "2024-07-12T21:45:01.996256Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
    "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
    "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
   ],
   "metadata": {
    "id": "m91cA0H5w_eY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def esm_embeddings(peptide_sequence_list):\n",
    "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
    "  #         or you have too many sequences for transformation in a single converting, \n",
    "  #         you conputer might automatically kill the job.\n",
    "  import torch\n",
    "  import esm\n",
    "  import collections\n",
    "  # load the model\n",
    "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
    "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "  batch_converter = alphabet.get_batch_converter()\n",
    "  model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "  # load the peptide sequence list into the bach_converter\n",
    "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
    "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "  ## batch tokens are the embedding results of the whole data set\n",
    "\n",
    "  # Extract per-residue representations (on CPU)\n",
    "  with torch.no_grad():\n",
    "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
    "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
    "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
    "  token_representations = results[\"representations\"][6]\n",
    "\n",
    "  # Generate per-sequence representations via averaging\n",
    "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "  sequence_representations = []\n",
    "  for i, tokens_len in enumerate(batch_lens):\n",
    "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "  # save dataset\n",
    "  # sequence_representations is a list and each element is a tensor\n",
    "  embeddings_results = collections.defaultdict(list)\n",
    "  for i in range(len(sequence_representations)):\n",
    "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
    "      each_seq_rep = sequence_representations[i].tolist()\n",
    "      for each_element in each_seq_rep:\n",
    "          embeddings_results[i].append(each_element)\n",
    "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
    "  return embeddings_results"
   ],
   "metadata": {
    "id": "pl7XVx5HZsHf",
    "ExecuteTime": {
     "end_time": "2024-07-12T21:45:17.425147Z",
     "start_time": "2024-07-12T21:45:17.403572Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### data loading and embeddings"
   ],
   "metadata": {
    "id": "RddxugbsdR1Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "id": "n6NOFoREw-40",
    "ExecuteTime": {
     "end_time": "2024-07-12T21:45:26.745379Z",
     "start_time": "2024-07-12T21:45:26.735378Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# training dataset loading\n",
    "dataset = pd.read_excel('APP_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
    "sequence_list = dataset['sequence'] \n",
    "\n",
    "embeddings_results = pd.DataFrame()\n",
    "for seq in sequence_list:\n",
    "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
    "    tuple_sequence = tuple(format_seq)\n",
    "    peptide_sequence_list = []\n",
    "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
    "    # employ ESM model for converting and save the converted data in csv format\n",
    "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
    "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
    "\n",
    "embeddings_results.to_csv('APP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
    "\n",
    "# loading the y dataset for model development \n",
    "y_train = dataset['label']\n",
    "y_train = np.array(y_train) # transformed as np.array for CNN model"
   ],
   "metadata": {
    "id": "LNlD8pvizH84",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d12e4bfb-dcfd-4125-fdb9-08ca1ce78779",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:08:14.996821Z",
     "start_time": "2024-07-12T21:46:23.603576Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt\" to C:\\Users\\harel/.cache\\torch\\hub\\checkpoints\\esm2_t6_8M_UR50D.pt\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t6_8M_UR50D-contact-regression.pt\" to C:\\Users\\harel/.cache\\torch\\hub\\checkpoints\\esm2_t6_8M_UR50D-contact-regression.pt\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# test dataset loading\n",
    "dataset = pd.read_excel('APP_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
    "sequence_list = dataset['sequence'] \n",
    "embeddings_results = pd.DataFrame()\n",
    "# embedding all the peptide one by one\n",
    "for seq in sequence_list:\n",
    "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
    "    tuple_sequence = tuple(format_seq)\n",
    "    peptide_sequence_list = []\n",
    "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
    "    # employ ESM model for converting and save the converted data in csv format\n",
    "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
    "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
    "\n",
    "embeddings_results.to_csv('APP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
    "\n",
    "\n",
    "# loading the y dataset for model development \n",
    "y_test = dataset['label']\n",
    "y_test = np.array(y_test) # transformed as np.array for CNN model"
   ],
   "metadata": {
    "id": "U7jxoIsCw8dW",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:08:51.364098Z",
     "start_time": "2024-07-12T22:08:14.997900Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# assign the dataset \n",
    "X_train_data_name = 'APP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
    "\n",
    "X_test_data_name = 'APP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
    "\n",
    "X_train = np.array(X_train_data)\n",
    "X_test = np.array(X_test_data)\n",
    "\n",
    "# normalize the X data range\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "id": "Xk13-JbBXAph",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:09:55.257403Z",
     "start_time": "2024-07-12T22:09:53.014113Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# check the dimension of the dataset before model development\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HubTATKXslKw",
    "outputId": "dc3962e5-b170-4df6-fe8c-39055110a86b",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:09:56.503631Z",
     "start_time": "2024-07-12T22:09:56.487487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2118, 320)\n",
      "(92, 320)\n",
      "(2118,)\n",
      "(92,)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# training dataset loading\n",
    "dataset = pd.read_excel('APP_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
    "sequence_list = dataset['sequence'] \n",
    "\n",
    "# loading the y dataset for model development \n",
    "y_train = dataset['label']\n",
    "y_train = np.array(y_train) # transformed as np.array for CNN model\n",
    "# test dataset loading\n",
    "dataset = pd.read_excel('APP_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
    "sequence_list = dataset['sequence'] \n",
    "# loading the y dataset for model development \n",
    "y_test = dataset['label']\n",
    "y_test = np.array(y_test) # transformed as np.array for CNN model\n",
    "# assign the dataset \n",
    "X_train_data_name = 'APP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
    "\n",
    "X_test_data_name = 'APP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
    "\n",
    "X_train = np.array(X_train_data)\n",
    "X_test = np.array(X_test_data)\n",
    "\n",
    "# normalize the X data range\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
    "X_test = scaler.transform(X_test)\n",
    "# check the dimension of the dataset before model development\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjtMdrIsWaXK",
    "outputId": "c98dd415-b56c-464c-c7cc-59711b4c10aa",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:42:10.322583Z",
     "start_time": "2024-07-12T22:42:09.761346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2118, 320)\n",
      "(92, 320)\n",
      "(2118,)\n",
      "(92,)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:13.671146Z",
     "start_time": "2024-07-12T23:01:13.656760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Shuffle y_train\n",
    "y_train = np.random.permutation(y_train)\n",
    "# Shuffle y_test\n",
    "y_test = np.random.permutation(y_test)\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:14.071092Z",
     "start_time": "2024-07-12T23:01:14.047219Z"
    }
   },
   "cell_type": "code",
   "source": "y_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": "### dataset undersampling",
   "metadata": {
    "id": "HK4AX-gdQptF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NearMiss-1 selects examples from the majority class that have the smallest average distance to the three closest examples from the minority class. NearMiss-2 selects examples from the majority class that have the smallest average distance to the three furthest examples from the minority class. NearMiss-3 involves selecting a given number of majority class examples for each example in the minority class that are closest."
   ],
   "metadata": {
    "id": "rAmtCjInShoO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NearMiss"
   ],
   "metadata": {
    "id": "jxxOPdukVsBb"
   }
  },
  {
   "cell_type": "code",
   "source": "# !pip install imbalanced-learn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVK5tkQeQ9Ud",
    "outputId": "501e9c57-8b1a-4c46-cb53-a8aec146bfc0",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:20.702626Z",
     "start_time": "2024-07-12T23:01:20.694149Z"
    }
   },
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "source": [
    "# NearMiss-1\n",
    "from imblearn.under_sampling import NearMiss\n",
    "# define the undersampling method\n",
    "undersample = NearMiss(sampling_strategy= 1, version=1, n_neighbors=3)\n",
    "# transform the dataset\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "id": "ro1zSZSHRpEV",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:21.118329Z",
     "start_time": "2024-07-12T23:01:21.066253Z"
    }
   },
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "source": [
    "# NearMiss-2\n",
    "from imblearn.under_sampling import NearMiss\n",
    "# define the undersampling method\n",
    "undersample = NearMiss(sampling_strategy= 1, version=2, n_neighbors=3)\n",
    "# transform the dataset\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "id": "pmwwy7NXTUmQ",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:21.859082Z",
     "start_time": "2024-07-12T23:01:21.802097Z"
    }
   },
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "# NearMiss-3\n",
    "from imblearn.under_sampling import NearMiss\n",
    "# define the undersampling method\n",
    "undersample = NearMiss(sampling_strategy= 1, version=3, n_neighbors=3)\n",
    "# transform the dataset\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "id": "Tx2pjEb4TVXp",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:22.205458Z",
     "start_time": "2024-07-12T23:01:22.148277Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:203: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "# check the dimension of the dataset before model development\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8IiywgHTAlB",
    "outputId": "614d1110-21f6-4015-994e-b7dffd9b7e1b",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:22.651953Z",
     "start_time": "2024-07-12T23:01:22.636228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 320)\n",
      "(92, 320)\n",
      "(426,)\n",
      "(92,)\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random select"
   ],
   "metadata": {
    "id": "JIFlBqL8Vum2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy=1,random_state = 0)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "id": "ck2w9rNbVwgc",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:24.446054Z",
     "start_time": "2024-07-12T23:01:24.416257Z"
    }
   },
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define undersampling strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority',random_state = 1)\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "id": "XmnWGPouWBHP",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:25.183048Z",
     "start_time": "2024-07-12T23:01:25.157297Z"
    }
   },
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "source": [
    "# check the dimension of the dataset before model development\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(np.count_nonzero(y_train == 0))\n",
    "print(np.count_nonzero(y_train == 1))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "888hbFrfWB1i",
    "outputId": "a09c8082-d0f5-446b-8865-5d5ce07ef18f",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:25.625677Z",
     "start_time": "2024-07-12T23:01:25.611507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 320)\n",
      "(92, 320)\n",
      "(510,)\n",
      "(92,)\n",
      "255\n",
      "255\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cluster Centroid"
   ],
   "metadata": {
    "id": "dZDHuiVJa_NA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "# define ClusterCentroids strategy\n",
    "CC = ClusterCentroids(sampling_strategy=1, random_state = 3)\n",
    "X_train, y_train = CC.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "id": "V3ZrLww4bA0N",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:52.532902Z",
     "start_time": "2024-07-12T23:01:26.611531Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\sklearn\\base.py:1152: ConvergenceWarning: Number of distinct clusters (171) found smaller than n_clusters (255). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "# check the dimension of the dataset before model development\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(np.count_nonzero(y_train == 0))\n",
    "print(np.count_nonzero(y_train == 1))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_oQZ6J5ghkU",
    "outputId": "efce1ae0-323b-4057-fed1-54a8892081ce",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:52.559698Z",
     "start_time": "2024-07-12T23:01:52.539358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 320)\n",
      "(92, 320)\n",
      "(510,)\n",
      "(92,)\n",
      "255\n",
      "255\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model architecture"
   ],
   "metadata": {
    "id": "U3Fagh9Iw83q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
    "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
    "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
    "  from keras.models import Sequential,Model\n",
    "  from keras.optimizers import SGD\n",
    "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
    "  import keras\n",
    "  from keras import backend as K\n",
    "  inputShape=(320,1)\n",
    "  input = Input(inputShape)\n",
    "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
    "  x = Dropout(0.15)(x)\n",
    "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
    "  x = Dropout(0.15)(x)\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
    "  x = Dropout(0.15)(x)\n",
    "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
    "  model = Model(inputs = input,outputs = x,name='Predict')\n",
    "  # define SGD optimizer\n",
    "  momentum = 0.5\n",
    "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
    "  # compile the model\n",
    "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
    "  # learning deccay setting\n",
    "  import math\n",
    "  def step_decay(epoch): # gradually decrease the learning rate \n",
    "      initial_lrate=0.1\n",
    "      drop=0.6\n",
    "      epochs_drop = 3.0\n",
    "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
    "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
    "      return lrate\n",
    "  lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "  # early stop setting\n",
    "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 40,restore_best_weights = True)\n",
    "\n",
    "  # summary the callbacks_list\n",
    "  callbacks_list = [ lrate , early_stop]\n",
    "######################\n",
    "  ######################\n",
    "  # HAREL: test is used ass validation!!!!\n",
    "  ######################\n",
    "  ######################\n",
    "  \n",
    "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                            epochs=200,callbacks=callbacks_list,batch_size = 8, verbose=2)\n",
    "  return model, model_history"
   ],
   "metadata": {
    "id": "b0QeK6-Cg_cv",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:01:52.616503Z",
     "start_time": "2024-07-12T23:01:52.561528Z"
    }
   },
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 10-fold cross validation"
   ],
   "metadata": {
    "id": "sws_G8h08tuq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Implementing 10-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "k = 10 \n",
    "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "\n",
    "for train_index , test_index in kf.split(y_train):\n",
    "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
    "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
    "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
    "    # confusion matrix \n",
    "    predicted_class= []\n",
    "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
    "    for i in range(predicted_protability.shape[0]):\n",
    "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
    "      predicted_class.append(index)\n",
    "    predicted_class = np.array(predicted_class)\n",
    "    y_true = y_valid_CV    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import math\n",
    "    # np.ravel() return a flatten 1D array\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "    ACC_collecton.append(ACC)\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
    "    AUC_collecton.append(AUC)\n"
   ],
   "metadata": {
    "id": "iFGZ88goj6u4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "01bd026e-81f4-4b8b-b7c5-a6bd746d4d29",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:10:44.612757Z",
     "start_time": "2024-07-12T23:01:52.624984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 - 4s - loss: 0.9852 - accuracy: 0.6623 - val_loss: 0.7968 - val_accuracy: 0.4510 - lr: 0.1000 - 4s/epoch - 74ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.4975 - accuracy: 0.7538 - val_loss: 0.7473 - val_accuracy: 0.4510 - lr: 0.1000 - 975ms/epoch - 17ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.4949 - accuracy: 0.8061 - val_loss: 0.8660 - val_accuracy: 0.4510 - lr: 0.0600 - 943ms/epoch - 16ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.4059 - accuracy: 0.8126 - val_loss: 0.9023 - val_accuracy: 0.4510 - lr: 0.0600 - 954ms/epoch - 16ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.3491 - accuracy: 0.8519 - val_loss: 0.8763 - val_accuracy: 0.4510 - lr: 0.0600 - 948ms/epoch - 16ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.3056 - accuracy: 0.8802 - val_loss: 0.7325 - val_accuracy: 0.5490 - lr: 0.0360 - 944ms/epoch - 16ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.3139 - accuracy: 0.8780 - val_loss: 0.5512 - val_accuracy: 0.7059 - lr: 0.0360 - 943ms/epoch - 16ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2924 - accuracy: 0.8932 - val_loss: 0.4073 - val_accuracy: 0.7843 - lr: 0.0360 - 950ms/epoch - 16ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2830 - accuracy: 0.8932 - val_loss: 0.3225 - val_accuracy: 0.8431 - lr: 0.0216 - 995ms/epoch - 17ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2829 - accuracy: 0.8845 - val_loss: 0.2957 - val_accuracy: 0.8824 - lr: 0.0216 - 966ms/epoch - 17ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2828 - accuracy: 0.8998 - val_loss: 0.2569 - val_accuracy: 0.9020 - lr: 0.0216 - 975ms/epoch - 17ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2765 - accuracy: 0.8976 - val_loss: 0.2562 - val_accuracy: 0.9020 - lr: 0.0130 - 923ms/epoch - 16ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2750 - accuracy: 0.8932 - val_loss: 0.2212 - val_accuracy: 0.9216 - lr: 0.0130 - 967ms/epoch - 17ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2738 - accuracy: 0.8976 - val_loss: 0.2419 - val_accuracy: 0.9216 - lr: 0.0130 - 1s/epoch - 17ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.2675 - accuracy: 0.9041 - val_loss: 0.2430 - val_accuracy: 0.9020 - lr: 0.0078 - 917ms/epoch - 16ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.2658 - accuracy: 0.9020 - val_loss: 0.2374 - val_accuracy: 0.9216 - lr: 0.0078 - 969ms/epoch - 17ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.2460 - accuracy: 0.9129 - val_loss: 0.2586 - val_accuracy: 0.8824 - lr: 0.0078 - 954ms/epoch - 16ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.2506 - accuracy: 0.9129 - val_loss: 0.2519 - val_accuracy: 0.8824 - lr: 0.0047 - 935ms/epoch - 16ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.2495 - accuracy: 0.9107 - val_loss: 0.2395 - val_accuracy: 0.9216 - lr: 0.0047 - 888ms/epoch - 15ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.2595 - accuracy: 0.9063 - val_loss: 0.2327 - val_accuracy: 0.9216 - lr: 0.0047 - 922ms/epoch - 16ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.2366 - accuracy: 0.9129 - val_loss: 0.2364 - val_accuracy: 0.9216 - lr: 0.0028 - 959ms/epoch - 17ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.2543 - accuracy: 0.9085 - val_loss: 0.2432 - val_accuracy: 0.9216 - lr: 0.0028 - 994ms/epoch - 17ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.2917 - accuracy: 0.8824 - val_loss: 0.2407 - val_accuracy: 0.9216 - lr: 0.0028 - 976ms/epoch - 17ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.2639 - accuracy: 0.9063 - val_loss: 0.2424 - val_accuracy: 0.9216 - lr: 0.0017 - 937ms/epoch - 16ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.2571 - accuracy: 0.9063 - val_loss: 0.2569 - val_accuracy: 0.8824 - lr: 0.0017 - 949ms/epoch - 16ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.2258 - accuracy: 0.9259 - val_loss: 0.2460 - val_accuracy: 0.9216 - lr: 0.0017 - 981ms/epoch - 17ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.2475 - accuracy: 0.9085 - val_loss: 0.2428 - val_accuracy: 0.9216 - lr: 0.0010 - 998ms/epoch - 17ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.2656 - accuracy: 0.8998 - val_loss: 0.2419 - val_accuracy: 0.9216 - lr: 0.0010 - 985ms/epoch - 17ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.2439 - accuracy: 0.9107 - val_loss: 0.2439 - val_accuracy: 0.9216 - lr: 0.0010 - 967ms/epoch - 17ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.2546 - accuracy: 0.9020 - val_loss: 0.2427 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 952ms/epoch - 16ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.2481 - accuracy: 0.9063 - val_loss: 0.2454 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 959ms/epoch - 17ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.2461 - accuracy: 0.9107 - val_loss: 0.2443 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 972ms/epoch - 17ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.2550 - accuracy: 0.9041 - val_loss: 0.2459 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 1s/epoch - 18ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.2513 - accuracy: 0.9150 - val_loss: 0.2465 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 944ms/epoch - 16ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.2457 - accuracy: 0.9107 - val_loss: 0.2485 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 930ms/epoch - 16ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.2386 - accuracy: 0.9129 - val_loss: 0.2487 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 939ms/epoch - 16ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.2546 - accuracy: 0.9063 - val_loss: 0.2501 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 939ms/epoch - 16ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.2432 - accuracy: 0.9107 - val_loss: 0.2494 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 976ms/epoch - 17ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.2329 - accuracy: 0.9194 - val_loss: 0.2493 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 1s/epoch - 18ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.2449 - accuracy: 0.9085 - val_loss: 0.2487 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 969ms/epoch - 17ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.2451 - accuracy: 0.9107 - val_loss: 0.2488 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 950ms/epoch - 16ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.2579 - accuracy: 0.9063 - val_loss: 0.2496 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 961ms/epoch - 17ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 1s - loss: 0.2373 - accuracy: 0.9194 - val_loss: 0.2494 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 961ms/epoch - 17ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.2346 - accuracy: 0.9172 - val_loss: 0.2510 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 936ms/epoch - 16ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.2400 - accuracy: 0.9172 - val_loss: 0.2510 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 946ms/epoch - 16ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.2592 - accuracy: 0.9041 - val_loss: 0.2513 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 918ms/epoch - 16ms/step\n",
      "Epoch 47/200\n",
      "58/58 - 1s - loss: 0.2770 - accuracy: 0.8845 - val_loss: 0.2507 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 876ms/epoch - 15ms/step\n",
      "Epoch 48/200\n",
      "58/58 - 1s - loss: 0.2282 - accuracy: 0.9281 - val_loss: 0.2507 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 853ms/epoch - 15ms/step\n",
      "Epoch 49/200\n",
      "58/58 - 1s - loss: 0.2346 - accuracy: 0.9172 - val_loss: 0.2505 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 875ms/epoch - 15ms/step\n",
      "Epoch 50/200\n",
      "58/58 - 1s - loss: 0.2496 - accuracy: 0.9085 - val_loss: 0.2503 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 881ms/epoch - 15ms/step\n",
      "Epoch 51/200\n",
      "58/58 - 1s - loss: 0.2463 - accuracy: 0.9020 - val_loss: 0.2504 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 866ms/epoch - 15ms/step\n",
      "Epoch 52/200\n",
      "58/58 - 1s - loss: 0.2536 - accuracy: 0.9107 - val_loss: 0.2498 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 832ms/epoch - 14ms/step\n",
      "Epoch 53/200\n",
      "58/58 - 1s - loss: 0.2349 - accuracy: 0.9194 - val_loss: 0.2503 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 847ms/epoch - 15ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 - 4s - loss: 1.3580 - accuracy: 0.6797 - val_loss: 0.6681 - val_accuracy: 0.6471 - lr: 0.1000 - 4s/epoch - 69ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.5191 - accuracy: 0.7647 - val_loss: 0.6831 - val_accuracy: 0.6471 - lr: 0.1000 - 954ms/epoch - 16ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.3822 - accuracy: 0.8214 - val_loss: 0.6795 - val_accuracy: 0.6667 - lr: 0.0600 - 807ms/epoch - 14ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.3542 - accuracy: 0.8540 - val_loss: 0.6405 - val_accuracy: 0.6471 - lr: 0.0600 - 821ms/epoch - 14ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.3315 - accuracy: 0.8540 - val_loss: 0.6168 - val_accuracy: 0.6667 - lr: 0.0600 - 771ms/epoch - 13ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.3034 - accuracy: 0.8627 - val_loss: 0.5288 - val_accuracy: 0.8824 - lr: 0.0360 - 779ms/epoch - 13ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.2618 - accuracy: 0.9063 - val_loss: 0.4326 - val_accuracy: 0.8824 - lr: 0.0360 - 823ms/epoch - 14ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2628 - accuracy: 0.8976 - val_loss: 0.3684 - val_accuracy: 0.8431 - lr: 0.0360 - 819ms/epoch - 14ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2551 - accuracy: 0.8889 - val_loss: 0.3382 - val_accuracy: 0.8627 - lr: 0.0216 - 967ms/epoch - 17ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2271 - accuracy: 0.9063 - val_loss: 0.3351 - val_accuracy: 0.8431 - lr: 0.0216 - 986ms/epoch - 17ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2063 - accuracy: 0.9216 - val_loss: 0.3468 - val_accuracy: 0.9020 - lr: 0.0216 - 993ms/epoch - 17ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2118 - accuracy: 0.9063 - val_loss: 0.3618 - val_accuracy: 0.8431 - lr: 0.0130 - 960ms/epoch - 17ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2194 - accuracy: 0.9063 - val_loss: 0.3403 - val_accuracy: 0.8627 - lr: 0.0130 - 880ms/epoch - 15ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2098 - accuracy: 0.9085 - val_loss: 0.3418 - val_accuracy: 0.9020 - lr: 0.0130 - 910ms/epoch - 16ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.1970 - accuracy: 0.9237 - val_loss: 0.3637 - val_accuracy: 0.8431 - lr: 0.0078 - 944ms/epoch - 16ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.1959 - accuracy: 0.9237 - val_loss: 0.3638 - val_accuracy: 0.8627 - lr: 0.0078 - 974ms/epoch - 17ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.2049 - accuracy: 0.9216 - val_loss: 0.4568 - val_accuracy: 0.8431 - lr: 0.0078 - 993ms/epoch - 17ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.1898 - accuracy: 0.9085 - val_loss: 0.3810 - val_accuracy: 0.8431 - lr: 0.0047 - 983ms/epoch - 17ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.1899 - accuracy: 0.9172 - val_loss: 0.3734 - val_accuracy: 0.8431 - lr: 0.0047 - 975ms/epoch - 17ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.1864 - accuracy: 0.9216 - val_loss: 0.3596 - val_accuracy: 0.9020 - lr: 0.0047 - 1s/epoch - 17ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.1894 - accuracy: 0.9216 - val_loss: 0.3720 - val_accuracy: 0.8431 - lr: 0.0028 - 888ms/epoch - 15ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.1859 - accuracy: 0.9172 - val_loss: 0.3774 - val_accuracy: 0.8431 - lr: 0.0028 - 955ms/epoch - 16ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.1852 - accuracy: 0.9194 - val_loss: 0.3763 - val_accuracy: 0.8431 - lr: 0.0028 - 981ms/epoch - 17ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.1789 - accuracy: 0.9237 - val_loss: 0.3775 - val_accuracy: 0.8431 - lr: 0.0017 - 953ms/epoch - 16ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.1800 - accuracy: 0.9281 - val_loss: 0.3806 - val_accuracy: 0.8431 - lr: 0.0017 - 906ms/epoch - 16ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.1822 - accuracy: 0.9259 - val_loss: 0.3954 - val_accuracy: 0.8235 - lr: 0.0017 - 930ms/epoch - 16ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.1675 - accuracy: 0.9346 - val_loss: 0.3943 - val_accuracy: 0.8235 - lr: 0.0010 - 939ms/epoch - 16ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.1963 - accuracy: 0.9150 - val_loss: 0.3916 - val_accuracy: 0.8235 - lr: 0.0010 - 959ms/epoch - 17ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.1864 - accuracy: 0.9085 - val_loss: 0.3988 - val_accuracy: 0.8235 - lr: 0.0010 - 971ms/epoch - 17ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.1941 - accuracy: 0.9085 - val_loss: 0.3895 - val_accuracy: 0.8431 - lr: 6.0466e-04 - 958ms/epoch - 17ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.1743 - accuracy: 0.9216 - val_loss: 0.3911 - val_accuracy: 0.8235 - lr: 6.0466e-04 - 977ms/epoch - 17ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.1744 - accuracy: 0.9216 - val_loss: 0.3953 - val_accuracy: 0.8235 - lr: 6.0466e-04 - 961ms/epoch - 17ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.1880 - accuracy: 0.9172 - val_loss: 0.3967 - val_accuracy: 0.8235 - lr: 3.6280e-04 - 978ms/epoch - 17ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.1719 - accuracy: 0.9259 - val_loss: 0.3946 - val_accuracy: 0.8235 - lr: 3.6280e-04 - 970ms/epoch - 17ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.1805 - accuracy: 0.9150 - val_loss: 0.3919 - val_accuracy: 0.8431 - lr: 3.6280e-04 - 979ms/epoch - 17ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.1768 - accuracy: 0.9237 - val_loss: 0.3918 - val_accuracy: 0.8431 - lr: 2.1768e-04 - 953ms/epoch - 16ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.1707 - accuracy: 0.9346 - val_loss: 0.3923 - val_accuracy: 0.8431 - lr: 2.1768e-04 - 974ms/epoch - 17ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.1703 - accuracy: 0.9194 - val_loss: 0.3920 - val_accuracy: 0.8431 - lr: 2.1768e-04 - 972ms/epoch - 17ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.1923 - accuracy: 0.9194 - val_loss: 0.3917 - val_accuracy: 0.8431 - lr: 1.3061e-04 - 978ms/epoch - 17ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.1749 - accuracy: 0.9237 - val_loss: 0.3911 - val_accuracy: 0.8431 - lr: 1.3061e-04 - 991ms/epoch - 17ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.1848 - accuracy: 0.9172 - val_loss: 0.3909 - val_accuracy: 0.8431 - lr: 1.3061e-04 - 921ms/epoch - 16ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.1813 - accuracy: 0.9237 - val_loss: 0.3905 - val_accuracy: 0.8431 - lr: 7.8364e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 1s - loss: 0.1773 - accuracy: 0.9172 - val_loss: 0.3908 - val_accuracy: 0.8431 - lr: 7.8364e-05 - 973ms/epoch - 17ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.1790 - accuracy: 0.9194 - val_loss: 0.3912 - val_accuracy: 0.8431 - lr: 7.8364e-05 - 999ms/epoch - 17ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.1831 - accuracy: 0.9172 - val_loss: 0.3927 - val_accuracy: 0.8431 - lr: 4.7018e-05 - 1s/epoch - 19ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.1841 - accuracy: 0.9216 - val_loss: 0.3925 - val_accuracy: 0.8431 - lr: 4.7018e-05 - 1s/epoch - 18ms/step\n",
      "Epoch 47/200\n",
      "58/58 - 1s - loss: 0.1785 - accuracy: 0.9259 - val_loss: 0.3927 - val_accuracy: 0.8431 - lr: 4.7018e-05 - 951ms/epoch - 16ms/step\n",
      "Epoch 48/200\n",
      "58/58 - 1s - loss: 0.1780 - accuracy: 0.9303 - val_loss: 0.3916 - val_accuracy: 0.8431 - lr: 2.8211e-05 - 976ms/epoch - 17ms/step\n",
      "Epoch 49/200\n",
      "58/58 - 1s - loss: 0.1916 - accuracy: 0.9085 - val_loss: 0.3923 - val_accuracy: 0.8431 - lr: 2.8211e-05 - 949ms/epoch - 16ms/step\n",
      "Epoch 50/200\n",
      "58/58 - 1s - loss: 0.1825 - accuracy: 0.9237 - val_loss: 0.3930 - val_accuracy: 0.8431 - lr: 2.8211e-05 - 914ms/epoch - 16ms/step\n",
      "Epoch 51/200\n",
      "58/58 - 1s - loss: 0.1815 - accuracy: 0.9172 - val_loss: 0.3913 - val_accuracy: 0.8431 - lr: 1.6927e-05 - 939ms/epoch - 16ms/step\n",
      "51/51 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 - 4s - loss: 2.2456 - accuracy: 0.7015 - val_loss: 3.0239 - val_accuracy: 0.5294 - lr: 0.1000 - 4s/epoch - 75ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.4358 - accuracy: 0.8279 - val_loss: 0.4923 - val_accuracy: 0.7451 - lr: 0.1000 - 930ms/epoch - 16ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.3783 - accuracy: 0.8540 - val_loss: 0.5550 - val_accuracy: 0.6667 - lr: 0.0600 - 949ms/epoch - 16ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.3208 - accuracy: 0.8606 - val_loss: 0.4256 - val_accuracy: 0.8039 - lr: 0.0600 - 997ms/epoch - 17ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.2921 - accuracy: 0.8845 - val_loss: 0.5126 - val_accuracy: 0.7451 - lr: 0.0600 - 933ms/epoch - 16ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.2882 - accuracy: 0.8954 - val_loss: 0.4046 - val_accuracy: 0.8235 - lr: 0.0360 - 876ms/epoch - 15ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.2532 - accuracy: 0.9063 - val_loss: 0.4349 - val_accuracy: 0.8235 - lr: 0.0360 - 837ms/epoch - 14ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2340 - accuracy: 0.9194 - val_loss: 0.4946 - val_accuracy: 0.7843 - lr: 0.0360 - 831ms/epoch - 14ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2035 - accuracy: 0.9259 - val_loss: 0.4937 - val_accuracy: 0.7843 - lr: 0.0216 - 860ms/epoch - 15ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2182 - accuracy: 0.9194 - val_loss: 0.4394 - val_accuracy: 0.7843 - lr: 0.0216 - 883ms/epoch - 15ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2053 - accuracy: 0.9216 - val_loss: 0.4472 - val_accuracy: 0.8235 - lr: 0.0216 - 820ms/epoch - 14ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.1876 - accuracy: 0.9303 - val_loss: 0.4352 - val_accuracy: 0.8235 - lr: 0.0130 - 838ms/epoch - 14ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.1968 - accuracy: 0.9259 - val_loss: 0.4475 - val_accuracy: 0.8039 - lr: 0.0130 - 823ms/epoch - 14ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.1997 - accuracy: 0.9259 - val_loss: 0.4185 - val_accuracy: 0.8039 - lr: 0.0130 - 850ms/epoch - 15ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.1921 - accuracy: 0.9237 - val_loss: 0.4480 - val_accuracy: 0.8235 - lr: 0.0078 - 802ms/epoch - 14ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.1904 - accuracy: 0.9237 - val_loss: 0.4425 - val_accuracy: 0.8039 - lr: 0.0078 - 788ms/epoch - 14ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.1798 - accuracy: 0.9281 - val_loss: 0.4367 - val_accuracy: 0.8235 - lr: 0.0078 - 928ms/epoch - 16ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.1701 - accuracy: 0.9368 - val_loss: 0.4484 - val_accuracy: 0.8235 - lr: 0.0047 - 944ms/epoch - 16ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.1799 - accuracy: 0.9216 - val_loss: 0.4414 - val_accuracy: 0.8235 - lr: 0.0047 - 976ms/epoch - 17ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.1744 - accuracy: 0.9237 - val_loss: 0.4569 - val_accuracy: 0.8235 - lr: 0.0047 - 936ms/epoch - 16ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.1694 - accuracy: 0.9259 - val_loss: 0.4640 - val_accuracy: 0.8235 - lr: 0.0028 - 917ms/epoch - 16ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.1589 - accuracy: 0.9346 - val_loss: 0.4585 - val_accuracy: 0.8235 - lr: 0.0028 - 959ms/epoch - 17ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.1696 - accuracy: 0.9346 - val_loss: 0.4508 - val_accuracy: 0.8235 - lr: 0.0028 - 971ms/epoch - 17ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.1677 - accuracy: 0.9281 - val_loss: 0.4512 - val_accuracy: 0.8235 - lr: 0.0017 - 929ms/epoch - 16ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.1707 - accuracy: 0.9303 - val_loss: 0.4469 - val_accuracy: 0.8235 - lr: 0.0017 - 953ms/epoch - 16ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.1651 - accuracy: 0.9368 - val_loss: 0.4531 - val_accuracy: 0.8235 - lr: 0.0017 - 960ms/epoch - 17ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.1622 - accuracy: 0.9281 - val_loss: 0.4545 - val_accuracy: 0.8235 - lr: 0.0010 - 963ms/epoch - 17ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.1601 - accuracy: 0.9281 - val_loss: 0.4538 - val_accuracy: 0.8235 - lr: 0.0010 - 957ms/epoch - 16ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.1588 - accuracy: 0.9412 - val_loss: 0.4548 - val_accuracy: 0.8235 - lr: 0.0010 - 904ms/epoch - 16ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.1642 - accuracy: 0.9303 - val_loss: 0.4542 - val_accuracy: 0.8235 - lr: 6.0466e-04 - 923ms/epoch - 16ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.1662 - accuracy: 0.9325 - val_loss: 0.4584 - val_accuracy: 0.8235 - lr: 6.0466e-04 - 948ms/epoch - 16ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.1632 - accuracy: 0.9390 - val_loss: 0.4599 - val_accuracy: 0.8235 - lr: 6.0466e-04 - 949ms/epoch - 16ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.1661 - accuracy: 0.9259 - val_loss: 0.4594 - val_accuracy: 0.8235 - lr: 3.6280e-04 - 935ms/epoch - 16ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.1686 - accuracy: 0.9216 - val_loss: 0.4598 - val_accuracy: 0.8235 - lr: 3.6280e-04 - 949ms/epoch - 16ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.1561 - accuracy: 0.9368 - val_loss: 0.4597 - val_accuracy: 0.8235 - lr: 3.6280e-04 - 981ms/epoch - 17ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.1619 - accuracy: 0.9368 - val_loss: 0.4591 - val_accuracy: 0.8235 - lr: 2.1768e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.1554 - accuracy: 0.9346 - val_loss: 0.4585 - val_accuracy: 0.8235 - lr: 2.1768e-04 - 926ms/epoch - 16ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.1661 - accuracy: 0.9390 - val_loss: 0.4594 - val_accuracy: 0.8235 - lr: 2.1768e-04 - 952ms/epoch - 16ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.1807 - accuracy: 0.9237 - val_loss: 0.4600 - val_accuracy: 0.8235 - lr: 1.3061e-04 - 891ms/epoch - 15ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.1654 - accuracy: 0.9368 - val_loss: 0.4601 - val_accuracy: 0.8235 - lr: 1.3061e-04 - 886ms/epoch - 15ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.1674 - accuracy: 0.9346 - val_loss: 0.4607 - val_accuracy: 0.8235 - lr: 1.3061e-04 - 937ms/epoch - 16ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.1736 - accuracy: 0.9303 - val_loss: 0.4608 - val_accuracy: 0.8235 - lr: 7.8364e-05 - 928ms/epoch - 16ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 1s - loss: 0.1542 - accuracy: 0.9434 - val_loss: 0.4612 - val_accuracy: 0.8235 - lr: 7.8364e-05 - 921ms/epoch - 16ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.1560 - accuracy: 0.9434 - val_loss: 0.4613 - val_accuracy: 0.8235 - lr: 7.8364e-05 - 948ms/epoch - 16ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.1618 - accuracy: 0.9325 - val_loss: 0.4613 - val_accuracy: 0.8235 - lr: 4.7018e-05 - 907ms/epoch - 16ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.1596 - accuracy: 0.9346 - val_loss: 0.4615 - val_accuracy: 0.8235 - lr: 4.7018e-05 - 974ms/epoch - 17ms/step\n",
      "51/51 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 - 4s - loss: 1.1948 - accuracy: 0.6013 - val_loss: 0.6985 - val_accuracy: 0.5098 - lr: 0.1000 - 4s/epoch - 74ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.4735 - accuracy: 0.7800 - val_loss: 0.7688 - val_accuracy: 0.5098 - lr: 0.1000 - 933ms/epoch - 16ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.3661 - accuracy: 0.8388 - val_loss: 0.8353 - val_accuracy: 0.5098 - lr: 0.0600 - 954ms/epoch - 16ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.3255 - accuracy: 0.8606 - val_loss: 0.7805 - val_accuracy: 0.5098 - lr: 0.0600 - 888ms/epoch - 15ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.2951 - accuracy: 0.8780 - val_loss: 0.7310 - val_accuracy: 0.5490 - lr: 0.0600 - 846ms/epoch - 15ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.2728 - accuracy: 0.8954 - val_loss: 0.6714 - val_accuracy: 0.6471 - lr: 0.0360 - 862ms/epoch - 15ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.2616 - accuracy: 0.8911 - val_loss: 0.5710 - val_accuracy: 0.7255 - lr: 0.0360 - 1s/epoch - 18ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2610 - accuracy: 0.9020 - val_loss: 0.4471 - val_accuracy: 0.7843 - lr: 0.0360 - 1s/epoch - 25ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 2s - loss: 0.2465 - accuracy: 0.9107 - val_loss: 0.4238 - val_accuracy: 0.8039 - lr: 0.0216 - 2s/epoch - 31ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2477 - accuracy: 0.9041 - val_loss: 0.4192 - val_accuracy: 0.8039 - lr: 0.0216 - 1s/epoch - 23ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2415 - accuracy: 0.9063 - val_loss: 0.3828 - val_accuracy: 0.8235 - lr: 0.0216 - 1s/epoch - 18ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2355 - accuracy: 0.9063 - val_loss: 0.3016 - val_accuracy: 0.8627 - lr: 0.0130 - 1s/epoch - 18ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2226 - accuracy: 0.9107 - val_loss: 0.3155 - val_accuracy: 0.8431 - lr: 0.0130 - 774ms/epoch - 13ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2152 - accuracy: 0.9216 - val_loss: 0.2931 - val_accuracy: 0.8627 - lr: 0.0130 - 636ms/epoch - 11ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.2155 - accuracy: 0.9194 - val_loss: 0.3072 - val_accuracy: 0.8627 - lr: 0.0078 - 612ms/epoch - 11ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.2203 - accuracy: 0.9172 - val_loss: 0.3048 - val_accuracy: 0.8431 - lr: 0.0078 - 645ms/epoch - 11ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.2265 - accuracy: 0.9150 - val_loss: 0.3002 - val_accuracy: 0.8627 - lr: 0.0078 - 683ms/epoch - 12ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.2137 - accuracy: 0.9216 - val_loss: 0.2896 - val_accuracy: 0.8627 - lr: 0.0047 - 660ms/epoch - 11ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.2127 - accuracy: 0.9194 - val_loss: 0.2977 - val_accuracy: 0.8627 - lr: 0.0047 - 642ms/epoch - 11ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.2085 - accuracy: 0.9216 - val_loss: 0.2946 - val_accuracy: 0.8627 - lr: 0.0047 - 722ms/epoch - 12ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.2045 - accuracy: 0.9259 - val_loss: 0.2945 - val_accuracy: 0.8627 - lr: 0.0028 - 824ms/epoch - 14ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.2070 - accuracy: 0.9259 - val_loss: 0.2989 - val_accuracy: 0.8627 - lr: 0.0028 - 785ms/epoch - 14ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.2066 - accuracy: 0.9303 - val_loss: 0.2962 - val_accuracy: 0.8824 - lr: 0.0028 - 813ms/epoch - 14ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.2049 - accuracy: 0.9281 - val_loss: 0.2997 - val_accuracy: 0.8824 - lr: 0.0017 - 816ms/epoch - 14ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.2006 - accuracy: 0.9303 - val_loss: 0.3011 - val_accuracy: 0.8824 - lr: 0.0017 - 855ms/epoch - 15ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.1997 - accuracy: 0.9281 - val_loss: 0.2978 - val_accuracy: 0.8824 - lr: 0.0017 - 806ms/epoch - 14ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.2004 - accuracy: 0.9259 - val_loss: 0.2974 - val_accuracy: 0.8824 - lr: 0.0010 - 812ms/epoch - 14ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.1952 - accuracy: 0.9346 - val_loss: 0.2993 - val_accuracy: 0.8824 - lr: 0.0010 - 843ms/epoch - 15ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.2037 - accuracy: 0.9281 - val_loss: 0.2996 - val_accuracy: 0.8824 - lr: 0.0010 - 831ms/epoch - 14ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.2059 - accuracy: 0.9281 - val_loss: 0.3008 - val_accuracy: 0.8824 - lr: 6.0466e-04 - 946ms/epoch - 16ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.2044 - accuracy: 0.9281 - val_loss: 0.3024 - val_accuracy: 0.8824 - lr: 6.0466e-04 - 955ms/epoch - 16ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.2024 - accuracy: 0.9281 - val_loss: 0.3013 - val_accuracy: 0.8824 - lr: 6.0466e-04 - 942ms/epoch - 16ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.1984 - accuracy: 0.9346 - val_loss: 0.3010 - val_accuracy: 0.8627 - lr: 3.6280e-04 - 985ms/epoch - 17ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.2056 - accuracy: 0.9237 - val_loss: 0.3010 - val_accuracy: 0.8627 - lr: 3.6280e-04 - 988ms/epoch - 17ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.2009 - accuracy: 0.9281 - val_loss: 0.3019 - val_accuracy: 0.8627 - lr: 3.6280e-04 - 1s/epoch - 18ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.2017 - accuracy: 0.9237 - val_loss: 0.3019 - val_accuracy: 0.8627 - lr: 2.1768e-04 - 919ms/epoch - 16ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.2077 - accuracy: 0.9259 - val_loss: 0.3021 - val_accuracy: 0.8627 - lr: 2.1768e-04 - 933ms/epoch - 16ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.1983 - accuracy: 0.9303 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 2.1768e-04 - 923ms/epoch - 16ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.2005 - accuracy: 0.9259 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 1.3061e-04 - 940ms/epoch - 16ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.1962 - accuracy: 0.9325 - val_loss: 0.3033 - val_accuracy: 0.8627 - lr: 1.3061e-04 - 944ms/epoch - 16ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.2063 - accuracy: 0.9281 - val_loss: 0.3032 - val_accuracy: 0.8627 - lr: 1.3061e-04 - 919ms/epoch - 16ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.2141 - accuracy: 0.9172 - val_loss: 0.3033 - val_accuracy: 0.8627 - lr: 7.8364e-05 - 968ms/epoch - 17ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 1s - loss: 0.2071 - accuracy: 0.9216 - val_loss: 0.3032 - val_accuracy: 0.8627 - lr: 7.8364e-05 - 856ms/epoch - 15ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.1967 - accuracy: 0.9281 - val_loss: 0.3031 - val_accuracy: 0.8627 - lr: 7.8364e-05 - 953ms/epoch - 16ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.2018 - accuracy: 0.9281 - val_loss: 0.3029 - val_accuracy: 0.8627 - lr: 4.7018e-05 - 891ms/epoch - 15ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.1990 - accuracy: 0.9281 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 4.7018e-05 - 939ms/epoch - 16ms/step\n",
      "Epoch 47/200\n",
      "58/58 - 1s - loss: 0.2152 - accuracy: 0.9194 - val_loss: 0.3029 - val_accuracy: 0.8627 - lr: 4.7018e-05 - 779ms/epoch - 13ms/step\n",
      "Epoch 48/200\n",
      "58/58 - 1s - loss: 0.2054 - accuracy: 0.9259 - val_loss: 0.3029 - val_accuracy: 0.8627 - lr: 2.8211e-05 - 841ms/epoch - 15ms/step\n",
      "Epoch 49/200\n",
      "58/58 - 1s - loss: 0.2096 - accuracy: 0.9259 - val_loss: 0.3028 - val_accuracy: 0.8627 - lr: 2.8211e-05 - 817ms/epoch - 14ms/step\n",
      "Epoch 50/200\n",
      "58/58 - 1s - loss: 0.2034 - accuracy: 0.9194 - val_loss: 0.3029 - val_accuracy: 0.8627 - lr: 2.8211e-05 - 829ms/epoch - 14ms/step\n",
      "Epoch 51/200\n",
      "58/58 - 1s - loss: 0.2035 - accuracy: 0.9237 - val_loss: 0.3029 - val_accuracy: 0.8627 - lr: 1.6927e-05 - 800ms/epoch - 14ms/step\n",
      "Epoch 52/200\n",
      "58/58 - 1s - loss: 0.2127 - accuracy: 0.9216 - val_loss: 0.3029 - val_accuracy: 0.8627 - lr: 1.6927e-05 - 833ms/epoch - 14ms/step\n",
      "Epoch 53/200\n",
      "58/58 - 1s - loss: 0.2041 - accuracy: 0.9216 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 1.6927e-05 - 845ms/epoch - 15ms/step\n",
      "Epoch 54/200\n",
      "58/58 - 1s - loss: 0.2027 - accuracy: 0.9259 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 1.0156e-05 - 849ms/epoch - 15ms/step\n",
      "Epoch 55/200\n",
      "58/58 - 1s - loss: 0.1956 - accuracy: 0.9325 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 1.0156e-05 - 799ms/epoch - 14ms/step\n",
      "Epoch 56/200\n",
      "58/58 - 1s - loss: 0.2021 - accuracy: 0.9325 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 1.0156e-05 - 833ms/epoch - 14ms/step\n",
      "Epoch 57/200\n",
      "58/58 - 1s - loss: 0.1977 - accuracy: 0.9303 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 6.0936e-06 - 840ms/epoch - 14ms/step\n",
      "Epoch 58/200\n",
      "58/58 - 1s - loss: 0.2069 - accuracy: 0.9237 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 6.0936e-06 - 809ms/epoch - 14ms/step\n",
      "Epoch 59/200\n",
      "58/58 - 1s - loss: 0.2040 - accuracy: 0.9237 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 6.0936e-06 - 827ms/epoch - 14ms/step\n",
      "Epoch 60/200\n",
      "58/58 - 1s - loss: 0.2112 - accuracy: 0.9194 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 3.6562e-06 - 895ms/epoch - 15ms/step\n",
      "Epoch 61/200\n",
      "58/58 - 1s - loss: 0.2086 - accuracy: 0.9194 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 3.6562e-06 - 964ms/epoch - 17ms/step\n",
      "Epoch 62/200\n",
      "58/58 - 1s - loss: 0.2073 - accuracy: 0.9259 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 3.6562e-06 - 988ms/epoch - 17ms/step\n",
      "Epoch 63/200\n",
      "58/58 - 1s - loss: 0.2021 - accuracy: 0.9259 - val_loss: 0.3030 - val_accuracy: 0.8627 - lr: 2.1937e-06 - 1s/epoch - 18ms/step\n",
      "51/51 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 - 4s - loss: 1.2151 - accuracy: 0.6296 - val_loss: 0.7090 - val_accuracy: 0.4902 - lr: 0.1000 - 4s/epoch - 75ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.6685 - accuracy: 0.5272 - val_loss: 0.6927 - val_accuracy: 0.4902 - lr: 0.1000 - 987ms/epoch - 17ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.5097 - accuracy: 0.7560 - val_loss: 0.7290 - val_accuracy: 0.4902 - lr: 0.0600 - 991ms/epoch - 17ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.4147 - accuracy: 0.8148 - val_loss: 0.7409 - val_accuracy: 0.5294 - lr: 0.0600 - 1s/epoch - 18ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.3480 - accuracy: 0.8519 - val_loss: 0.6210 - val_accuracy: 0.6667 - lr: 0.0600 - 962ms/epoch - 17ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.3187 - accuracy: 0.8736 - val_loss: 0.5383 - val_accuracy: 0.6863 - lr: 0.0360 - 996ms/epoch - 17ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.3122 - accuracy: 0.8802 - val_loss: 0.4947 - val_accuracy: 0.7647 - lr: 0.0360 - 998ms/epoch - 17ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2777 - accuracy: 0.8911 - val_loss: 0.4371 - val_accuracy: 0.8039 - lr: 0.0360 - 861ms/epoch - 15ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2572 - accuracy: 0.9085 - val_loss: 0.4067 - val_accuracy: 0.8235 - lr: 0.0216 - 884ms/epoch - 15ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2426 - accuracy: 0.9150 - val_loss: 0.4017 - val_accuracy: 0.8235 - lr: 0.0216 - 923ms/epoch - 16ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2342 - accuracy: 0.9194 - val_loss: 0.3521 - val_accuracy: 0.8627 - lr: 0.0216 - 877ms/epoch - 15ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2463 - accuracy: 0.9085 - val_loss: 0.3119 - val_accuracy: 0.8824 - lr: 0.0130 - 872ms/epoch - 15ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2344 - accuracy: 0.9107 - val_loss: 0.3585 - val_accuracy: 0.8431 - lr: 0.0130 - 988ms/epoch - 17ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2499 - accuracy: 0.9085 - val_loss: 0.3104 - val_accuracy: 0.8627 - lr: 0.0130 - 917ms/epoch - 16ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.2320 - accuracy: 0.9172 - val_loss: 0.3196 - val_accuracy: 0.8627 - lr: 0.0078 - 869ms/epoch - 15ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.2456 - accuracy: 0.9150 - val_loss: 0.3103 - val_accuracy: 0.9020 - lr: 0.0078 - 885ms/epoch - 15ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.2431 - accuracy: 0.9107 - val_loss: 0.3152 - val_accuracy: 0.8627 - lr: 0.0078 - 867ms/epoch - 15ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.2213 - accuracy: 0.9259 - val_loss: 0.2992 - val_accuracy: 0.8824 - lr: 0.0047 - 922ms/epoch - 16ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.2134 - accuracy: 0.9303 - val_loss: 0.2799 - val_accuracy: 0.9020 - lr: 0.0047 - 780ms/epoch - 13ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.2226 - accuracy: 0.9259 - val_loss: 0.3059 - val_accuracy: 0.8824 - lr: 0.0047 - 813ms/epoch - 14ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.2279 - accuracy: 0.9172 - val_loss: 0.2924 - val_accuracy: 0.9020 - lr: 0.0028 - 889ms/epoch - 15ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.2140 - accuracy: 0.9259 - val_loss: 0.2790 - val_accuracy: 0.9020 - lr: 0.0028 - 816ms/epoch - 14ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.2408 - accuracy: 0.9129 - val_loss: 0.3014 - val_accuracy: 0.9020 - lr: 0.0028 - 857ms/epoch - 15ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.2338 - accuracy: 0.9150 - val_loss: 0.2921 - val_accuracy: 0.9020 - lr: 0.0017 - 812ms/epoch - 14ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.2291 - accuracy: 0.9194 - val_loss: 0.2914 - val_accuracy: 0.9020 - lr: 0.0017 - 797ms/epoch - 14ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.2323 - accuracy: 0.9216 - val_loss: 0.2916 - val_accuracy: 0.9020 - lr: 0.0017 - 898ms/epoch - 15ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.2151 - accuracy: 0.9259 - val_loss: 0.2930 - val_accuracy: 0.9020 - lr: 0.0010 - 870ms/epoch - 15ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.2231 - accuracy: 0.9259 - val_loss: 0.2896 - val_accuracy: 0.9020 - lr: 0.0010 - 824ms/epoch - 14ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.2304 - accuracy: 0.9172 - val_loss: 0.2867 - val_accuracy: 0.9020 - lr: 0.0010 - 816ms/epoch - 14ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.2183 - accuracy: 0.9259 - val_loss: 0.2878 - val_accuracy: 0.9020 - lr: 6.0466e-04 - 910ms/epoch - 16ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.2293 - accuracy: 0.9194 - val_loss: 0.2883 - val_accuracy: 0.9020 - lr: 6.0466e-04 - 800ms/epoch - 14ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.2212 - accuracy: 0.9216 - val_loss: 0.2879 - val_accuracy: 0.9020 - lr: 6.0466e-04 - 951ms/epoch - 16ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.2201 - accuracy: 0.9237 - val_loss: 0.2892 - val_accuracy: 0.9020 - lr: 3.6280e-04 - 942ms/epoch - 16ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.2162 - accuracy: 0.9259 - val_loss: 0.2886 - val_accuracy: 0.9020 - lr: 3.6280e-04 - 887ms/epoch - 15ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.2209 - accuracy: 0.9237 - val_loss: 0.2889 - val_accuracy: 0.9020 - lr: 3.6280e-04 - 953ms/epoch - 16ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.2109 - accuracy: 0.9303 - val_loss: 0.2892 - val_accuracy: 0.9020 - lr: 2.1768e-04 - 897ms/epoch - 15ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.2253 - accuracy: 0.9194 - val_loss: 0.2890 - val_accuracy: 0.9020 - lr: 2.1768e-04 - 857ms/epoch - 15ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.2102 - accuracy: 0.9259 - val_loss: 0.2887 - val_accuracy: 0.9020 - lr: 2.1768e-04 - 853ms/epoch - 15ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.2310 - accuracy: 0.9150 - val_loss: 0.2883 - val_accuracy: 0.9020 - lr: 1.3061e-04 - 882ms/epoch - 15ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.2225 - accuracy: 0.9281 - val_loss: 0.2887 - val_accuracy: 0.9020 - lr: 1.3061e-04 - 873ms/epoch - 15ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.2235 - accuracy: 0.9216 - val_loss: 0.2880 - val_accuracy: 0.9020 - lr: 1.3061e-04 - 882ms/epoch - 15ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.2095 - accuracy: 0.9281 - val_loss: 0.2878 - val_accuracy: 0.9020 - lr: 7.8364e-05 - 890ms/epoch - 15ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 1s - loss: 0.2140 - accuracy: 0.9281 - val_loss: 0.2880 - val_accuracy: 0.9020 - lr: 7.8364e-05 - 861ms/epoch - 15ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.2124 - accuracy: 0.9325 - val_loss: 0.2875 - val_accuracy: 0.9020 - lr: 7.8364e-05 - 893ms/epoch - 15ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.2114 - accuracy: 0.9237 - val_loss: 0.2879 - val_accuracy: 0.9020 - lr: 4.7018e-05 - 843ms/epoch - 15ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.2155 - accuracy: 0.9259 - val_loss: 0.2876 - val_accuracy: 0.9020 - lr: 4.7018e-05 - 848ms/epoch - 15ms/step\n",
      "Epoch 47/200\n",
      "58/58 - 1s - loss: 0.2124 - accuracy: 0.9281 - val_loss: 0.2878 - val_accuracy: 0.9020 - lr: 4.7018e-05 - 846ms/epoch - 15ms/step\n",
      "Epoch 48/200\n",
      "58/58 - 1s - loss: 0.2088 - accuracy: 0.9325 - val_loss: 0.2877 - val_accuracy: 0.9020 - lr: 2.8211e-05 - 845ms/epoch - 15ms/step\n",
      "Epoch 49/200\n",
      "58/58 - 1s - loss: 0.2042 - accuracy: 0.9303 - val_loss: 0.2877 - val_accuracy: 0.9020 - lr: 2.8211e-05 - 878ms/epoch - 15ms/step\n",
      "Epoch 50/200\n",
      "58/58 - 1s - loss: 0.2133 - accuracy: 0.9303 - val_loss: 0.2875 - val_accuracy: 0.9020 - lr: 2.8211e-05 - 847ms/epoch - 15ms/step\n",
      "Epoch 51/200\n",
      "58/58 - 1s - loss: 0.2244 - accuracy: 0.9172 - val_loss: 0.2877 - val_accuracy: 0.9020 - lr: 1.6927e-05 - 985ms/epoch - 17ms/step\n",
      "Epoch 52/200\n",
      "58/58 - 1s - loss: 0.2124 - accuracy: 0.9281 - val_loss: 0.2878 - val_accuracy: 0.9020 - lr: 1.6927e-05 - 980ms/epoch - 17ms/step\n",
      "Epoch 53/200\n",
      "58/58 - 1s - loss: 0.2222 - accuracy: 0.9237 - val_loss: 0.2880 - val_accuracy: 0.9020 - lr: 1.6927e-05 - 937ms/epoch - 16ms/step\n",
      "Epoch 54/200\n",
      "58/58 - 1s - loss: 0.2180 - accuracy: 0.9216 - val_loss: 0.2877 - val_accuracy: 0.9020 - lr: 1.0156e-05 - 909ms/epoch - 16ms/step\n",
      "Epoch 55/200\n",
      "58/58 - 1s - loss: 0.2233 - accuracy: 0.9216 - val_loss: 0.2877 - val_accuracy: 0.9020 - lr: 1.0156e-05 - 876ms/epoch - 15ms/step\n",
      "Epoch 56/200\n",
      "58/58 - 1s - loss: 0.2233 - accuracy: 0.9259 - val_loss: 0.2876 - val_accuracy: 0.9020 - lr: 1.0156e-05 - 981ms/epoch - 17ms/step\n",
      "51/51 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 - 4s - loss: 1.4898 - accuracy: 0.7233 - val_loss: 0.7107 - val_accuracy: 0.4706 - lr: 0.1000 - 4s/epoch - 68ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.4541 - accuracy: 0.8301 - val_loss: 0.6995 - val_accuracy: 0.4706 - lr: 0.1000 - 905ms/epoch - 16ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.3281 - accuracy: 0.8627 - val_loss: 0.6899 - val_accuracy: 0.5294 - lr: 0.0600 - 967ms/epoch - 17ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.3024 - accuracy: 0.8715 - val_loss: 0.6835 - val_accuracy: 0.6078 - lr: 0.0600 - 961ms/epoch - 17ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.2847 - accuracy: 0.8954 - val_loss: 0.6397 - val_accuracy: 0.6667 - lr: 0.0600 - 841ms/epoch - 15ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.2688 - accuracy: 0.8889 - val_loss: 0.5681 - val_accuracy: 0.8039 - lr: 0.0360 - 900ms/epoch - 16ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.2427 - accuracy: 0.9063 - val_loss: 0.4322 - val_accuracy: 0.8824 - lr: 0.0360 - 928ms/epoch - 16ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2569 - accuracy: 0.8932 - val_loss: 0.3945 - val_accuracy: 0.8627 - lr: 0.0360 - 894ms/epoch - 15ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2389 - accuracy: 0.9020 - val_loss: 0.3173 - val_accuracy: 0.8824 - lr: 0.0216 - 942ms/epoch - 16ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2362 - accuracy: 0.9063 - val_loss: 0.3255 - val_accuracy: 0.8824 - lr: 0.0216 - 967ms/epoch - 17ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2131 - accuracy: 0.9085 - val_loss: 0.2958 - val_accuracy: 0.9020 - lr: 0.0216 - 996ms/epoch - 17ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2179 - accuracy: 0.9107 - val_loss: 0.2965 - val_accuracy: 0.9020 - lr: 0.0130 - 987ms/epoch - 17ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2027 - accuracy: 0.9259 - val_loss: 0.2888 - val_accuracy: 0.9020 - lr: 0.0130 - 1s/epoch - 18ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2103 - accuracy: 0.9194 - val_loss: 0.2969 - val_accuracy: 0.9020 - lr: 0.0130 - 957ms/epoch - 16ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.1911 - accuracy: 0.9259 - val_loss: 0.2952 - val_accuracy: 0.9216 - lr: 0.0078 - 979ms/epoch - 17ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.1960 - accuracy: 0.9237 - val_loss: 0.2909 - val_accuracy: 0.9020 - lr: 0.0078 - 1s/epoch - 17ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.1825 - accuracy: 0.9259 - val_loss: 0.2924 - val_accuracy: 0.9020 - lr: 0.0078 - 956ms/epoch - 16ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.1773 - accuracy: 0.9259 - val_loss: 0.2926 - val_accuracy: 0.9216 - lr: 0.0047 - 1s/epoch - 18ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.1899 - accuracy: 0.9281 - val_loss: 0.2891 - val_accuracy: 0.9020 - lr: 0.0047 - 989ms/epoch - 17ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.1906 - accuracy: 0.9237 - val_loss: 0.2894 - val_accuracy: 0.9216 - lr: 0.0047 - 987ms/epoch - 17ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.1629 - accuracy: 0.9325 - val_loss: 0.2902 - val_accuracy: 0.9216 - lr: 0.0028 - 983ms/epoch - 17ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.1783 - accuracy: 0.9281 - val_loss: 0.2920 - val_accuracy: 0.9216 - lr: 0.0028 - 992ms/epoch - 17ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.1740 - accuracy: 0.9346 - val_loss: 0.2914 - val_accuracy: 0.9020 - lr: 0.0028 - 992ms/epoch - 17ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.1835 - accuracy: 0.9259 - val_loss: 0.2901 - val_accuracy: 0.9020 - lr: 0.0017 - 963ms/epoch - 17ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.1766 - accuracy: 0.9259 - val_loss: 0.2907 - val_accuracy: 0.9216 - lr: 0.0017 - 948ms/epoch - 16ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.1775 - accuracy: 0.9237 - val_loss: 0.2924 - val_accuracy: 0.9216 - lr: 0.0017 - 949ms/epoch - 16ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.1685 - accuracy: 0.9325 - val_loss: 0.2923 - val_accuracy: 0.9216 - lr: 0.0010 - 885ms/epoch - 15ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.1793 - accuracy: 0.9303 - val_loss: 0.2914 - val_accuracy: 0.9216 - lr: 0.0010 - 926ms/epoch - 16ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.1776 - accuracy: 0.9303 - val_loss: 0.2908 - val_accuracy: 0.9216 - lr: 0.0010 - 930ms/epoch - 16ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.1748 - accuracy: 0.9368 - val_loss: 0.2911 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 912ms/epoch - 16ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.1640 - accuracy: 0.9325 - val_loss: 0.2912 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 892ms/epoch - 15ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.1791 - accuracy: 0.9237 - val_loss: 0.2913 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 900ms/epoch - 16ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.1704 - accuracy: 0.9303 - val_loss: 0.2914 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 896ms/epoch - 15ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.1648 - accuracy: 0.9325 - val_loss: 0.2916 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 927ms/epoch - 16ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.1698 - accuracy: 0.9281 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 905ms/epoch - 16ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.1658 - accuracy: 0.9303 - val_loss: 0.2920 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 963ms/epoch - 17ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.1799 - accuracy: 0.9216 - val_loss: 0.2918 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 947ms/epoch - 16ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.1723 - accuracy: 0.9216 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 936ms/epoch - 16ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.1652 - accuracy: 0.9346 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 908ms/epoch - 16ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.1612 - accuracy: 0.9325 - val_loss: 0.2918 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 907ms/epoch - 16ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.1620 - accuracy: 0.9390 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 1s/epoch - 18ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.1646 - accuracy: 0.9412 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 1s/epoch - 18ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 2s - loss: 0.1715 - accuracy: 0.9368 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 2s/epoch - 28ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 2s - loss: 0.1643 - accuracy: 0.9368 - val_loss: 0.2918 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 2s/epoch - 27ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.1670 - accuracy: 0.9346 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 964ms/epoch - 17ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.1653 - accuracy: 0.9237 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 1s/epoch - 20ms/step\n",
      "Epoch 47/200\n",
      "58/58 - 1s - loss: 0.1662 - accuracy: 0.9368 - val_loss: 0.2918 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 1s/epoch - 20ms/step\n",
      "Epoch 48/200\n",
      "58/58 - 1s - loss: 0.1662 - accuracy: 0.9412 - val_loss: 0.2918 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 777ms/epoch - 13ms/step\n",
      "Epoch 49/200\n",
      "58/58 - 1s - loss: 0.1720 - accuracy: 0.9303 - val_loss: 0.2917 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 745ms/epoch - 13ms/step\n",
      "Epoch 50/200\n",
      "58/58 - 1s - loss: 0.1609 - accuracy: 0.9368 - val_loss: 0.2918 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 621ms/epoch - 11ms/step\n",
      "Epoch 51/200\n",
      "58/58 - 1s - loss: 0.1650 - accuracy: 0.9303 - val_loss: 0.2920 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 602ms/epoch - 10ms/step\n",
      "Epoch 52/200\n",
      "58/58 - 1s - loss: 0.1759 - accuracy: 0.9303 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 695ms/epoch - 12ms/step\n",
      "Epoch 53/200\n",
      "58/58 - 1s - loss: 0.1758 - accuracy: 0.9368 - val_loss: 0.2918 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 631ms/epoch - 11ms/step\n",
      "Epoch 54/200\n",
      "58/58 - 1s - loss: 0.1747 - accuracy: 0.9216 - val_loss: 0.2920 - val_accuracy: 0.9216 - lr: 1.0156e-05 - 648ms/epoch - 11ms/step\n",
      "Epoch 55/200\n",
      "58/58 - 1s - loss: 0.1795 - accuracy: 0.9281 - val_loss: 0.2919 - val_accuracy: 0.9216 - lr: 1.0156e-05 - 670ms/epoch - 12ms/step\n",
      "51/51 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 - 3s - loss: 2.1676 - accuracy: 0.6405 - val_loss: 0.6542 - val_accuracy: 0.5686 - lr: 0.1000 - 3s/epoch - 44ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.4279 - accuracy: 0.8279 - val_loss: 0.6736 - val_accuracy: 0.6078 - lr: 0.1000 - 620ms/epoch - 11ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.3668 - accuracy: 0.8497 - val_loss: 0.5329 - val_accuracy: 0.8627 - lr: 0.0600 - 580ms/epoch - 10ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.3160 - accuracy: 0.8758 - val_loss: 0.4702 - val_accuracy: 0.8824 - lr: 0.0600 - 605ms/epoch - 10ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.3166 - accuracy: 0.8780 - val_loss: 0.5093 - val_accuracy: 0.7647 - lr: 0.0600 - 616ms/epoch - 11ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.2869 - accuracy: 0.8780 - val_loss: 0.4078 - val_accuracy: 0.8627 - lr: 0.0360 - 558ms/epoch - 10ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.2709 - accuracy: 0.8998 - val_loss: 0.4383 - val_accuracy: 0.8627 - lr: 0.0360 - 592ms/epoch - 10ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2481 - accuracy: 0.8976 - val_loss: 0.4679 - val_accuracy: 0.8431 - lr: 0.0360 - 652ms/epoch - 11ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2351 - accuracy: 0.9063 - val_loss: 0.3467 - val_accuracy: 0.8431 - lr: 0.0216 - 651ms/epoch - 11ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2448 - accuracy: 0.9041 - val_loss: 0.3632 - val_accuracy: 0.8431 - lr: 0.0216 - 634ms/epoch - 11ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2406 - accuracy: 0.9150 - val_loss: 0.3729 - val_accuracy: 0.8431 - lr: 0.0216 - 601ms/epoch - 10ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2310 - accuracy: 0.9194 - val_loss: 0.3585 - val_accuracy: 0.8431 - lr: 0.0130 - 620ms/epoch - 11ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2249 - accuracy: 0.9216 - val_loss: 0.3428 - val_accuracy: 0.8627 - lr: 0.0130 - 617ms/epoch - 11ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2251 - accuracy: 0.9129 - val_loss: 0.3429 - val_accuracy: 0.8627 - lr: 0.0130 - 576ms/epoch - 10ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.2119 - accuracy: 0.9172 - val_loss: 0.3854 - val_accuracy: 0.8431 - lr: 0.0078 - 655ms/epoch - 11ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.2038 - accuracy: 0.9150 - val_loss: 0.3502 - val_accuracy: 0.8431 - lr: 0.0078 - 595ms/epoch - 10ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.1895 - accuracy: 0.9281 - val_loss: 0.3540 - val_accuracy: 0.8627 - lr: 0.0078 - 567ms/epoch - 10ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.2231 - accuracy: 0.9063 - val_loss: 0.3523 - val_accuracy: 0.8431 - lr: 0.0047 - 716ms/epoch - 12ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.2173 - accuracy: 0.9107 - val_loss: 0.3468 - val_accuracy: 0.8431 - lr: 0.0047 - 620ms/epoch - 11ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.2060 - accuracy: 0.9085 - val_loss: 0.3435 - val_accuracy: 0.8431 - lr: 0.0047 - 633ms/epoch - 11ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.2049 - accuracy: 0.9259 - val_loss: 0.3587 - val_accuracy: 0.8431 - lr: 0.0028 - 673ms/epoch - 12ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.1877 - accuracy: 0.9346 - val_loss: 0.3521 - val_accuracy: 0.8431 - lr: 0.0028 - 711ms/epoch - 12ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.2038 - accuracy: 0.9216 - val_loss: 0.3605 - val_accuracy: 0.8431 - lr: 0.0028 - 621ms/epoch - 11ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.2113 - accuracy: 0.9172 - val_loss: 0.3542 - val_accuracy: 0.8431 - lr: 0.0017 - 641ms/epoch - 11ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.1976 - accuracy: 0.9172 - val_loss: 0.3507 - val_accuracy: 0.8431 - lr: 0.0017 - 613ms/epoch - 11ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.2101 - accuracy: 0.9194 - val_loss: 0.3496 - val_accuracy: 0.8431 - lr: 0.0017 - 654ms/epoch - 11ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.2050 - accuracy: 0.9063 - val_loss: 0.3519 - val_accuracy: 0.8431 - lr: 0.0010 - 612ms/epoch - 11ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.1988 - accuracy: 0.9216 - val_loss: 0.3600 - val_accuracy: 0.8431 - lr: 0.0010 - 611ms/epoch - 11ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.1885 - accuracy: 0.9281 - val_loss: 0.3561 - val_accuracy: 0.8431 - lr: 0.0010 - 636ms/epoch - 11ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.1880 - accuracy: 0.9259 - val_loss: 0.3582 - val_accuracy: 0.8431 - lr: 6.0466e-04 - 578ms/epoch - 10ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.2009 - accuracy: 0.9281 - val_loss: 0.3667 - val_accuracy: 0.8235 - lr: 6.0466e-04 - 632ms/epoch - 11ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.2068 - accuracy: 0.9194 - val_loss: 0.3627 - val_accuracy: 0.8235 - lr: 6.0466e-04 - 652ms/epoch - 11ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.1917 - accuracy: 0.9259 - val_loss: 0.3604 - val_accuracy: 0.8431 - lr: 3.6280e-04 - 610ms/epoch - 11ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.2031 - accuracy: 0.9194 - val_loss: 0.3610 - val_accuracy: 0.8431 - lr: 3.6280e-04 - 732ms/epoch - 13ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.2158 - accuracy: 0.9172 - val_loss: 0.3592 - val_accuracy: 0.8431 - lr: 3.6280e-04 - 731ms/epoch - 13ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.1833 - accuracy: 0.9216 - val_loss: 0.3603 - val_accuracy: 0.8431 - lr: 2.1768e-04 - 727ms/epoch - 13ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.1941 - accuracy: 0.9346 - val_loss: 0.3596 - val_accuracy: 0.8431 - lr: 2.1768e-04 - 615ms/epoch - 11ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.2033 - accuracy: 0.9172 - val_loss: 0.3581 - val_accuracy: 0.8431 - lr: 2.1768e-04 - 631ms/epoch - 11ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.1835 - accuracy: 0.9237 - val_loss: 0.3578 - val_accuracy: 0.8431 - lr: 1.3061e-04 - 580ms/epoch - 10ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.1833 - accuracy: 0.9281 - val_loss: 0.3577 - val_accuracy: 0.8431 - lr: 1.3061e-04 - 636ms/epoch - 11ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.1817 - accuracy: 0.9259 - val_loss: 0.3583 - val_accuracy: 0.8431 - lr: 1.3061e-04 - 642ms/epoch - 11ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.1967 - accuracy: 0.9172 - val_loss: 0.3586 - val_accuracy: 0.8431 - lr: 7.8364e-05 - 857ms/epoch - 15ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 1s - loss: 0.1990 - accuracy: 0.9216 - val_loss: 0.3579 - val_accuracy: 0.8431 - lr: 7.8364e-05 - 917ms/epoch - 16ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.1907 - accuracy: 0.9216 - val_loss: 0.3576 - val_accuracy: 0.8431 - lr: 7.8364e-05 - 957ms/epoch - 16ms/step\n",
      "51/51 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 - 4s - loss: 0.9191 - accuracy: 0.5534 - val_loss: 0.7204 - val_accuracy: 0.4706 - lr: 0.1000 - 4s/epoch - 64ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.5896 - accuracy: 0.6972 - val_loss: 0.7565 - val_accuracy: 0.4706 - lr: 0.1000 - 976ms/epoch - 17ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.5661 - accuracy: 0.6841 - val_loss: 0.7610 - val_accuracy: 0.4706 - lr: 0.0600 - 938ms/epoch - 16ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.4617 - accuracy: 0.7669 - val_loss: 0.7333 - val_accuracy: 0.4902 - lr: 0.0600 - 977ms/epoch - 17ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.3725 - accuracy: 0.8519 - val_loss: 0.6599 - val_accuracy: 0.6275 - lr: 0.0600 - 920ms/epoch - 16ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.3256 - accuracy: 0.8627 - val_loss: 0.4923 - val_accuracy: 0.7451 - lr: 0.0360 - 1s/epoch - 17ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.3325 - accuracy: 0.8540 - val_loss: 0.4554 - val_accuracy: 0.7843 - lr: 0.0360 - 993ms/epoch - 17ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2971 - accuracy: 0.8802 - val_loss: 0.3871 - val_accuracy: 0.8039 - lr: 0.0360 - 990ms/epoch - 17ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2889 - accuracy: 0.8758 - val_loss: 0.3000 - val_accuracy: 0.8431 - lr: 0.0216 - 997ms/epoch - 17ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2793 - accuracy: 0.8845 - val_loss: 0.2628 - val_accuracy: 0.8431 - lr: 0.0216 - 982ms/epoch - 17ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2939 - accuracy: 0.8758 - val_loss: 0.2253 - val_accuracy: 0.9020 - lr: 0.0216 - 1s/epoch - 17ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2864 - accuracy: 0.8758 - val_loss: 0.2290 - val_accuracy: 0.9020 - lr: 0.0130 - 981ms/epoch - 17ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2621 - accuracy: 0.8954 - val_loss: 0.2095 - val_accuracy: 0.9412 - lr: 0.0130 - 1s/epoch - 18ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2586 - accuracy: 0.8976 - val_loss: 0.1923 - val_accuracy: 0.9412 - lr: 0.0130 - 989ms/epoch - 17ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.2652 - accuracy: 0.8932 - val_loss: 0.2206 - val_accuracy: 0.9412 - lr: 0.0078 - 986ms/epoch - 17ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.2388 - accuracy: 0.9107 - val_loss: 0.1864 - val_accuracy: 0.9412 - lr: 0.0078 - 992ms/epoch - 17ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.2538 - accuracy: 0.9020 - val_loss: 0.1923 - val_accuracy: 0.9216 - lr: 0.0078 - 999ms/epoch - 17ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.2459 - accuracy: 0.9041 - val_loss: 0.1920 - val_accuracy: 0.9412 - lr: 0.0047 - 1s/epoch - 17ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.2345 - accuracy: 0.9063 - val_loss: 0.1785 - val_accuracy: 0.9412 - lr: 0.0047 - 989ms/epoch - 17ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.2431 - accuracy: 0.9085 - val_loss: 0.1803 - val_accuracy: 0.9412 - lr: 0.0047 - 997ms/epoch - 17ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.2487 - accuracy: 0.8998 - val_loss: 0.1821 - val_accuracy: 0.9412 - lr: 0.0028 - 1s/epoch - 17ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.2421 - accuracy: 0.9063 - val_loss: 0.1900 - val_accuracy: 0.9216 - lr: 0.0028 - 988ms/epoch - 17ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.2334 - accuracy: 0.9063 - val_loss: 0.1990 - val_accuracy: 0.9216 - lr: 0.0028 - 1s/epoch - 17ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.2349 - accuracy: 0.9041 - val_loss: 0.2025 - val_accuracy: 0.9216 - lr: 0.0017 - 1s/epoch - 17ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.2454 - accuracy: 0.9041 - val_loss: 0.2064 - val_accuracy: 0.9216 - lr: 0.0017 - 977ms/epoch - 17ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.2246 - accuracy: 0.9150 - val_loss: 0.2142 - val_accuracy: 0.9216 - lr: 0.0017 - 1s/epoch - 18ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.2429 - accuracy: 0.8998 - val_loss: 0.2080 - val_accuracy: 0.9216 - lr: 0.0010 - 895ms/epoch - 15ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.2504 - accuracy: 0.8976 - val_loss: 0.2156 - val_accuracy: 0.9216 - lr: 0.0010 - 872ms/epoch - 15ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.2483 - accuracy: 0.9020 - val_loss: 0.2126 - val_accuracy: 0.9216 - lr: 0.0010 - 990ms/epoch - 17ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.2398 - accuracy: 0.9041 - val_loss: 0.2140 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 938ms/epoch - 16ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.2205 - accuracy: 0.9172 - val_loss: 0.2143 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 719ms/epoch - 12ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.2365 - accuracy: 0.9063 - val_loss: 0.2142 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 643ms/epoch - 11ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.2192 - accuracy: 0.9194 - val_loss: 0.2140 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 595ms/epoch - 10ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.2182 - accuracy: 0.9150 - val_loss: 0.2144 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 610ms/epoch - 11ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.2376 - accuracy: 0.9041 - val_loss: 0.2122 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 622ms/epoch - 11ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.2526 - accuracy: 0.8998 - val_loss: 0.2129 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 620ms/epoch - 11ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.2577 - accuracy: 0.8867 - val_loss: 0.2126 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 627ms/epoch - 11ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.2382 - accuracy: 0.9041 - val_loss: 0.2138 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 618ms/epoch - 11ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.2317 - accuracy: 0.9020 - val_loss: 0.2150 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 636ms/epoch - 11ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.2296 - accuracy: 0.9129 - val_loss: 0.2145 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 627ms/epoch - 11ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.2302 - accuracy: 0.9150 - val_loss: 0.2139 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 680ms/epoch - 12ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.2307 - accuracy: 0.9085 - val_loss: 0.2143 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 632ms/epoch - 11ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 1s - loss: 0.2446 - accuracy: 0.8976 - val_loss: 0.2138 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 680ms/epoch - 12ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.2393 - accuracy: 0.8954 - val_loss: 0.2138 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 630ms/epoch - 11ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.2366 - accuracy: 0.9063 - val_loss: 0.2133 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 716ms/epoch - 12ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.2371 - accuracy: 0.9020 - val_loss: 0.2131 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 632ms/epoch - 11ms/step\n",
      "Epoch 47/200\n",
      "58/58 - 1s - loss: 0.2406 - accuracy: 0.9041 - val_loss: 0.2125 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 700ms/epoch - 12ms/step\n",
      "Epoch 48/200\n",
      "58/58 - 1s - loss: 0.2255 - accuracy: 0.9150 - val_loss: 0.2124 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 672ms/epoch - 12ms/step\n",
      "Epoch 49/200\n",
      "58/58 - 1s - loss: 0.2364 - accuracy: 0.9041 - val_loss: 0.2125 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 635ms/epoch - 11ms/step\n",
      "Epoch 50/200\n",
      "58/58 - 1s - loss: 0.2242 - accuracy: 0.9172 - val_loss: 0.2126 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 652ms/epoch - 11ms/step\n",
      "Epoch 51/200\n",
      "58/58 - 1s - loss: 0.2255 - accuracy: 0.9107 - val_loss: 0.2127 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 597ms/epoch - 10ms/step\n",
      "Epoch 52/200\n",
      "58/58 - 1s - loss: 0.2249 - accuracy: 0.9150 - val_loss: 0.2126 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 660ms/epoch - 11ms/step\n",
      "Epoch 53/200\n",
      "58/58 - 1s - loss: 0.2450 - accuracy: 0.9020 - val_loss: 0.2126 - val_accuracy: 0.9216 - lr: 1.6927e-05 - 650ms/epoch - 11ms/step\n",
      "51/51 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 - 4s - loss: 2.4819 - accuracy: 0.6688 - val_loss: 0.6248 - val_accuracy: 0.5098 - lr: 0.1000 - 4s/epoch - 61ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.4470 - accuracy: 0.8039 - val_loss: 0.5913 - val_accuracy: 0.5098 - lr: 0.1000 - 604ms/epoch - 10ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.3493 - accuracy: 0.8606 - val_loss: 0.4115 - val_accuracy: 0.8627 - lr: 0.0600 - 683ms/epoch - 12ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.3315 - accuracy: 0.8649 - val_loss: 0.2633 - val_accuracy: 0.9216 - lr: 0.0600 - 657ms/epoch - 11ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.3101 - accuracy: 0.8736 - val_loss: 0.3109 - val_accuracy: 0.8431 - lr: 0.0600 - 623ms/epoch - 11ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.3502 - accuracy: 0.8475 - val_loss: 0.2244 - val_accuracy: 0.9216 - lr: 0.0360 - 582ms/epoch - 10ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.3002 - accuracy: 0.8824 - val_loss: 0.2189 - val_accuracy: 0.9216 - lr: 0.0360 - 638ms/epoch - 11ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2825 - accuracy: 0.8802 - val_loss: 0.2202 - val_accuracy: 0.9412 - lr: 0.0360 - 640ms/epoch - 11ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2510 - accuracy: 0.9020 - val_loss: 0.2152 - val_accuracy: 0.8824 - lr: 0.0216 - 594ms/epoch - 10ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2583 - accuracy: 0.8954 - val_loss: 0.2199 - val_accuracy: 0.9020 - lr: 0.0216 - 606ms/epoch - 10ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2734 - accuracy: 0.8932 - val_loss: 0.2075 - val_accuracy: 0.9216 - lr: 0.0216 - 596ms/epoch - 10ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2579 - accuracy: 0.9041 - val_loss: 0.2042 - val_accuracy: 0.9216 - lr: 0.0130 - 586ms/epoch - 10ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2285 - accuracy: 0.9129 - val_loss: 0.2067 - val_accuracy: 0.9216 - lr: 0.0130 - 628ms/epoch - 11ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2520 - accuracy: 0.9020 - val_loss: 0.2090 - val_accuracy: 0.9216 - lr: 0.0130 - 605ms/epoch - 10ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.2384 - accuracy: 0.9085 - val_loss: 0.2088 - val_accuracy: 0.9216 - lr: 0.0078 - 616ms/epoch - 11ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.2199 - accuracy: 0.9172 - val_loss: 0.2028 - val_accuracy: 0.9216 - lr: 0.0078 - 659ms/epoch - 11ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 1s - loss: 0.2390 - accuracy: 0.9107 - val_loss: 0.2078 - val_accuracy: 0.9216 - lr: 0.0078 - 592ms/epoch - 10ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 1s - loss: 0.2180 - accuracy: 0.9194 - val_loss: 0.2099 - val_accuracy: 0.9216 - lr: 0.0047 - 639ms/epoch - 11ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.2241 - accuracy: 0.9107 - val_loss: 0.2055 - val_accuracy: 0.9216 - lr: 0.0047 - 599ms/epoch - 10ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.2343 - accuracy: 0.9150 - val_loss: 0.2117 - val_accuracy: 0.9216 - lr: 0.0047 - 643ms/epoch - 11ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.2269 - accuracy: 0.9063 - val_loss: 0.2072 - val_accuracy: 0.9216 - lr: 0.0028 - 626ms/epoch - 11ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.2350 - accuracy: 0.9085 - val_loss: 0.2060 - val_accuracy: 0.9216 - lr: 0.0028 - 633ms/epoch - 11ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.2313 - accuracy: 0.8998 - val_loss: 0.2073 - val_accuracy: 0.9216 - lr: 0.0028 - 664ms/epoch - 11ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.2248 - accuracy: 0.9129 - val_loss: 0.2091 - val_accuracy: 0.9216 - lr: 0.0017 - 617ms/epoch - 11ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 1s - loss: 0.2166 - accuracy: 0.9150 - val_loss: 0.2097 - val_accuracy: 0.9216 - lr: 0.0017 - 653ms/epoch - 11ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 2s - loss: 0.2352 - accuracy: 0.8976 - val_loss: 0.2091 - val_accuracy: 0.9216 - lr: 0.0017 - 2s/epoch - 26ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.2331 - accuracy: 0.9150 - val_loss: 0.2100 - val_accuracy: 0.9216 - lr: 0.0010 - 1s/epoch - 20ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.2158 - accuracy: 0.9172 - val_loss: 0.2087 - val_accuracy: 0.9216 - lr: 0.0010 - 1s/epoch - 18ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.2139 - accuracy: 0.9281 - val_loss: 0.2073 - val_accuracy: 0.9216 - lr: 0.0010 - 1s/epoch - 19ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.2208 - accuracy: 0.9107 - val_loss: 0.2065 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 616ms/epoch - 11ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.2166 - accuracy: 0.9085 - val_loss: 0.2070 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 673ms/epoch - 12ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.2264 - accuracy: 0.9063 - val_loss: 0.2077 - val_accuracy: 0.9216 - lr: 6.0466e-04 - 632ms/epoch - 11ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.2236 - accuracy: 0.9063 - val_loss: 0.2074 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 692ms/epoch - 12ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.2152 - accuracy: 0.9129 - val_loss: 0.2080 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 688ms/epoch - 12ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.2141 - accuracy: 0.9216 - val_loss: 0.2082 - val_accuracy: 0.9216 - lr: 3.6280e-04 - 690ms/epoch - 12ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.2282 - accuracy: 0.9129 - val_loss: 0.2083 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 711ms/epoch - 12ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.2129 - accuracy: 0.9150 - val_loss: 0.2082 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 656ms/epoch - 11ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.2403 - accuracy: 0.9020 - val_loss: 0.2083 - val_accuracy: 0.9216 - lr: 2.1768e-04 - 614ms/epoch - 11ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.2211 - accuracy: 0.9150 - val_loss: 0.2083 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 700ms/epoch - 12ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.2237 - accuracy: 0.9150 - val_loss: 0.2085 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 671ms/epoch - 12ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.2199 - accuracy: 0.9041 - val_loss: 0.2086 - val_accuracy: 0.9216 - lr: 1.3061e-04 - 618ms/epoch - 11ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.2157 - accuracy: 0.9216 - val_loss: 0.2088 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 699ms/epoch - 12ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 1s - loss: 0.2364 - accuracy: 0.9041 - val_loss: 0.2087 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 609ms/epoch - 10ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.2150 - accuracy: 0.9172 - val_loss: 0.2086 - val_accuracy: 0.9216 - lr: 7.8364e-05 - 608ms/epoch - 10ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.2162 - accuracy: 0.9107 - val_loss: 0.2085 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 624ms/epoch - 11ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.2110 - accuracy: 0.9129 - val_loss: 0.2086 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 567ms/epoch - 10ms/step\n",
      "Epoch 47/200\n",
      "58/58 - 1s - loss: 0.2219 - accuracy: 0.9150 - val_loss: 0.2086 - val_accuracy: 0.9216 - lr: 4.7018e-05 - 582ms/epoch - 10ms/step\n",
      "Epoch 48/200\n",
      "58/58 - 1s - loss: 0.2208 - accuracy: 0.9172 - val_loss: 0.2086 - val_accuracy: 0.9216 - lr: 2.8211e-05 - 642ms/epoch - 11ms/step\n",
      "51/51 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 - 3s - loss: 1.6166 - accuracy: 0.6449 - val_loss: 0.6299 - val_accuracy: 0.8039 - lr: 0.1000 - 3s/epoch - 44ms/step\n",
      "Epoch 2/200\n",
      "58/58 - 1s - loss: 0.4453 - accuracy: 0.7974 - val_loss: 0.6462 - val_accuracy: 0.5686 - lr: 0.1000 - 655ms/epoch - 11ms/step\n",
      "Epoch 3/200\n",
      "58/58 - 1s - loss: 0.3209 - accuracy: 0.8758 - val_loss: 0.5408 - val_accuracy: 0.7451 - lr: 0.0600 - 642ms/epoch - 11ms/step\n",
      "Epoch 4/200\n",
      "58/58 - 1s - loss: 0.3771 - accuracy: 0.8431 - val_loss: 0.5800 - val_accuracy: 0.6863 - lr: 0.0600 - 622ms/epoch - 11ms/step\n",
      "Epoch 5/200\n",
      "58/58 - 1s - loss: 0.3256 - accuracy: 0.8671 - val_loss: 0.4845 - val_accuracy: 0.7451 - lr: 0.0600 - 665ms/epoch - 11ms/step\n",
      "Epoch 6/200\n",
      "58/58 - 1s - loss: 0.3039 - accuracy: 0.8780 - val_loss: 0.3896 - val_accuracy: 0.8235 - lr: 0.0360 - 691ms/epoch - 12ms/step\n",
      "Epoch 7/200\n",
      "58/58 - 1s - loss: 0.2840 - accuracy: 0.8780 - val_loss: 0.2834 - val_accuracy: 0.8627 - lr: 0.0360 - 627ms/epoch - 11ms/step\n",
      "Epoch 8/200\n",
      "58/58 - 1s - loss: 0.2868 - accuracy: 0.8824 - val_loss: 0.2680 - val_accuracy: 0.8824 - lr: 0.0360 - 607ms/epoch - 10ms/step\n",
      "Epoch 9/200\n",
      "58/58 - 1s - loss: 0.2679 - accuracy: 0.8845 - val_loss: 0.2117 - val_accuracy: 0.9216 - lr: 0.0216 - 585ms/epoch - 10ms/step\n",
      "Epoch 10/200\n",
      "58/58 - 1s - loss: 0.2525 - accuracy: 0.8954 - val_loss: 0.2038 - val_accuracy: 0.9216 - lr: 0.0216 - 592ms/epoch - 10ms/step\n",
      "Epoch 11/200\n",
      "58/58 - 1s - loss: 0.2552 - accuracy: 0.8954 - val_loss: 0.1827 - val_accuracy: 0.9412 - lr: 0.0216 - 666ms/epoch - 11ms/step\n",
      "Epoch 12/200\n",
      "58/58 - 1s - loss: 0.2360 - accuracy: 0.9020 - val_loss: 0.1580 - val_accuracy: 0.9608 - lr: 0.0130 - 608ms/epoch - 10ms/step\n",
      "Epoch 13/200\n",
      "58/58 - 1s - loss: 0.2337 - accuracy: 0.9085 - val_loss: 0.1599 - val_accuracy: 0.9608 - lr: 0.0130 - 650ms/epoch - 11ms/step\n",
      "Epoch 14/200\n",
      "58/58 - 1s - loss: 0.2359 - accuracy: 0.9020 - val_loss: 0.1736 - val_accuracy: 0.9412 - lr: 0.0130 - 608ms/epoch - 10ms/step\n",
      "Epoch 15/200\n",
      "58/58 - 1s - loss: 0.2232 - accuracy: 0.9150 - val_loss: 0.1643 - val_accuracy: 0.9608 - lr: 0.0078 - 565ms/epoch - 10ms/step\n",
      "Epoch 16/200\n",
      "58/58 - 1s - loss: 0.2386 - accuracy: 0.9020 - val_loss: 0.1673 - val_accuracy: 0.9608 - lr: 0.0078 - 668ms/epoch - 12ms/step\n",
      "Epoch 17/200\n",
      "58/58 - 3s - loss: 0.2173 - accuracy: 0.9085 - val_loss: 0.1740 - val_accuracy: 0.9412 - lr: 0.0078 - 3s/epoch - 45ms/step\n",
      "Epoch 18/200\n",
      "58/58 - 2s - loss: 0.2238 - accuracy: 0.9129 - val_loss: 0.1762 - val_accuracy: 0.9412 - lr: 0.0047 - 2s/epoch - 38ms/step\n",
      "Epoch 19/200\n",
      "58/58 - 1s - loss: 0.2271 - accuracy: 0.9063 - val_loss: 0.1722 - val_accuracy: 0.9412 - lr: 0.0047 - 1s/epoch - 20ms/step\n",
      "Epoch 20/200\n",
      "58/58 - 1s - loss: 0.2035 - accuracy: 0.9259 - val_loss: 0.1707 - val_accuracy: 0.9412 - lr: 0.0047 - 1s/epoch - 24ms/step\n",
      "Epoch 21/200\n",
      "58/58 - 1s - loss: 0.2194 - accuracy: 0.9150 - val_loss: 0.1740 - val_accuracy: 0.9412 - lr: 0.0028 - 944ms/epoch - 16ms/step\n",
      "Epoch 22/200\n",
      "58/58 - 1s - loss: 0.2045 - accuracy: 0.9237 - val_loss: 0.1701 - val_accuracy: 0.9412 - lr: 0.0028 - 904ms/epoch - 16ms/step\n",
      "Epoch 23/200\n",
      "58/58 - 1s - loss: 0.2087 - accuracy: 0.9129 - val_loss: 0.1749 - val_accuracy: 0.9412 - lr: 0.0028 - 807ms/epoch - 14ms/step\n",
      "Epoch 24/200\n",
      "58/58 - 1s - loss: 0.2205 - accuracy: 0.9150 - val_loss: 0.1764 - val_accuracy: 0.9412 - lr: 0.0017 - 878ms/epoch - 15ms/step\n",
      "Epoch 25/200\n",
      "58/58 - 2s - loss: 0.2028 - accuracy: 0.9237 - val_loss: 0.1738 - val_accuracy: 0.9412 - lr: 0.0017 - 2s/epoch - 26ms/step\n",
      "Epoch 26/200\n",
      "58/58 - 1s - loss: 0.2085 - accuracy: 0.9216 - val_loss: 0.1741 - val_accuracy: 0.9412 - lr: 0.0017 - 1s/epoch - 22ms/step\n",
      "Epoch 27/200\n",
      "58/58 - 1s - loss: 0.2030 - accuracy: 0.9237 - val_loss: 0.1750 - val_accuracy: 0.9412 - lr: 0.0010 - 925ms/epoch - 16ms/step\n",
      "Epoch 28/200\n",
      "58/58 - 1s - loss: 0.1985 - accuracy: 0.9194 - val_loss: 0.1745 - val_accuracy: 0.9412 - lr: 0.0010 - 816ms/epoch - 14ms/step\n",
      "Epoch 29/200\n",
      "58/58 - 1s - loss: 0.2135 - accuracy: 0.9259 - val_loss: 0.1745 - val_accuracy: 0.9412 - lr: 0.0010 - 810ms/epoch - 14ms/step\n",
      "Epoch 30/200\n",
      "58/58 - 1s - loss: 0.2083 - accuracy: 0.9172 - val_loss: 0.1731 - val_accuracy: 0.9412 - lr: 6.0466e-04 - 793ms/epoch - 14ms/step\n",
      "Epoch 31/200\n",
      "58/58 - 1s - loss: 0.2081 - accuracy: 0.9237 - val_loss: 0.1745 - val_accuracy: 0.9412 - lr: 6.0466e-04 - 769ms/epoch - 13ms/step\n",
      "Epoch 32/200\n",
      "58/58 - 1s - loss: 0.2110 - accuracy: 0.9194 - val_loss: 0.1763 - val_accuracy: 0.9412 - lr: 6.0466e-04 - 935ms/epoch - 16ms/step\n",
      "Epoch 33/200\n",
      "58/58 - 1s - loss: 0.2011 - accuracy: 0.9237 - val_loss: 0.1761 - val_accuracy: 0.9412 - lr: 3.6280e-04 - 639ms/epoch - 11ms/step\n",
      "Epoch 34/200\n",
      "58/58 - 1s - loss: 0.2078 - accuracy: 0.9172 - val_loss: 0.1764 - val_accuracy: 0.9412 - lr: 3.6280e-04 - 896ms/epoch - 15ms/step\n",
      "Epoch 35/200\n",
      "58/58 - 1s - loss: 0.2148 - accuracy: 0.9150 - val_loss: 0.1760 - val_accuracy: 0.9412 - lr: 3.6280e-04 - 775ms/epoch - 13ms/step\n",
      "Epoch 36/200\n",
      "58/58 - 1s - loss: 0.2078 - accuracy: 0.9172 - val_loss: 0.1759 - val_accuracy: 0.9412 - lr: 2.1768e-04 - 684ms/epoch - 12ms/step\n",
      "Epoch 37/200\n",
      "58/58 - 1s - loss: 0.1988 - accuracy: 0.9325 - val_loss: 0.1754 - val_accuracy: 0.9412 - lr: 2.1768e-04 - 1s/epoch - 22ms/step\n",
      "Epoch 38/200\n",
      "58/58 - 1s - loss: 0.1961 - accuracy: 0.9259 - val_loss: 0.1755 - val_accuracy: 0.9412 - lr: 2.1768e-04 - 858ms/epoch - 15ms/step\n",
      "Epoch 39/200\n",
      "58/58 - 1s - loss: 0.2072 - accuracy: 0.9107 - val_loss: 0.1750 - val_accuracy: 0.9412 - lr: 1.3061e-04 - 1s/epoch - 23ms/step\n",
      "Epoch 40/200\n",
      "58/58 - 1s - loss: 0.2071 - accuracy: 0.9194 - val_loss: 0.1749 - val_accuracy: 0.9412 - lr: 1.3061e-04 - 1s/epoch - 20ms/step\n",
      "Epoch 41/200\n",
      "58/58 - 1s - loss: 0.1978 - accuracy: 0.9194 - val_loss: 0.1747 - val_accuracy: 0.9412 - lr: 1.3061e-04 - 882ms/epoch - 15ms/step\n",
      "Epoch 42/200\n",
      "58/58 - 1s - loss: 0.2097 - accuracy: 0.9172 - val_loss: 0.1746 - val_accuracy: 0.9412 - lr: 7.8364e-05 - 1s/epoch - 20ms/step\n",
      "Epoch 43/200\n",
      "58/58 - 2s - loss: 0.2082 - accuracy: 0.9172 - val_loss: 0.1747 - val_accuracy: 0.9412 - lr: 7.8364e-05 - 2s/epoch - 32ms/step\n",
      "Epoch 44/200\n",
      "58/58 - 1s - loss: 0.2061 - accuracy: 0.9259 - val_loss: 0.1746 - val_accuracy: 0.9412 - lr: 7.8364e-05 - 936ms/epoch - 16ms/step\n",
      "Epoch 45/200\n",
      "58/58 - 1s - loss: 0.2091 - accuracy: 0.9172 - val_loss: 0.1746 - val_accuracy: 0.9412 - lr: 4.7018e-05 - 1s/epoch - 23ms/step\n",
      "Epoch 46/200\n",
      "58/58 - 1s - loss: 0.1877 - accuracy: 0.9346 - val_loss: 0.1747 - val_accuracy: 0.9412 - lr: 4.7018e-05 - 1s/epoch - 18ms/step\n",
      "Epoch 47/200\n",
      "58/58 - 1s - loss: 0.2162 - accuracy: 0.9129 - val_loss: 0.1746 - val_accuracy: 0.9412 - lr: 4.7018e-05 - 1s/epoch - 18ms/step\n",
      "Epoch 48/200\n",
      "58/58 - 1s - loss: 0.2044 - accuracy: 0.9259 - val_loss: 0.1745 - val_accuracy: 0.9412 - lr: 2.8211e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 49/200\n",
      "58/58 - 1s - loss: 0.2197 - accuracy: 0.9150 - val_loss: 0.1746 - val_accuracy: 0.9412 - lr: 2.8211e-05 - 1s/epoch - 20ms/step\n",
      "Epoch 50/200\n",
      "58/58 - 1s - loss: 0.2044 - accuracy: 0.9172 - val_loss: 0.1745 - val_accuracy: 0.9412 - lr: 2.8211e-05 - 1s/epoch - 18ms/step\n",
      "Epoch 51/200\n",
      "58/58 - 1s - loss: 0.1932 - accuracy: 0.9259 - val_loss: 0.1745 - val_accuracy: 0.9412 - lr: 1.6927e-05 - 1s/epoch - 19ms/step\n",
      "Epoch 52/200\n",
      "58/58 - 1s - loss: 0.2033 - accuracy: 0.9172 - val_loss: 0.1745 - val_accuracy: 0.9412 - lr: 1.6927e-05 - 1s/epoch - 20ms/step\n",
      "51/51 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": [
    "from statistics import mean, stdev\n",
    "print(mean(ACC_collecton),'',stdev(ACC_collecton))\n",
    "print(mean(BACC_collecton),'',stdev(BACC_collecton))\n",
    "print(mean(Sn_collecton),'',stdev(Sn_collecton))\n",
    "print(mean(Sp_collecton),'',stdev(Sp_collecton))\n",
    "print(mean(MCC_collecton),'',stdev(MCC_collecton))\n",
    "print(mean(AUC_collecton),'',stdev(AUC_collecton))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTi2x37MzsIY",
    "outputId": "ca6b5ab8-2d6c-4bea-d6e1-f4486481fa89",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:10:44.700828Z",
     "start_time": "2024-07-12T23:10:44.615991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907843137254902  0.03927011473411714\n",
      "0.9187015805122181  0.037450078663330916\n",
      "0.9861471861471861  0.030935474045279358\n",
      "0.85125597487725  0.050911222016377794\n",
      "0.8246166829868402  0.07528877247879974\n",
      "0.9149141633904253  0.042544786753747725\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [
    "ACC_collecton"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "397sLYBohyh7",
    "outputId": "7cca9c4f-0da1-4f80-9bf3-b7da2713807b",
    "ExecuteTime": {
     "end_time": "2024-07-12T23:10:44.732991Z",
     "start_time": "2024-07-12T23:10:44.701453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9215686274509803,\n",
       " 0.9019607843137255,\n",
       " 0.8235294117647058,\n",
       " 0.8823529411764706,\n",
       " 0.9019607843137255,\n",
       " 0.9215686274509803,\n",
       " 0.8823529411764706,\n",
       " 0.9411764705882353,\n",
       " 0.9411764705882353,\n",
       " 0.9607843137254902]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model evaluation in test dataset"
   ],
   "metadata": {
    "id": "5JBlTA9shnQE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "######################\n",
    "#HARE: Notice how test is passed on as validation!!!!!!\n",
    "######################\n",
    "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
    "# confusion matrix \n",
    "predicted_class= []\n",
    "predicted_protability = model.predict(X_test,batch_size=1)\n",
    "for i in range(predicted_protability.shape[0]):\n",
    "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
    "  predicted_class.append(index)\n",
    "predicted_class = np.array(predicted_class)\n",
    "y_true = y_test    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "# np.ravel() return a flatten 1D array\n",
    "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "ACC_collecton.append(ACC)\n",
    "Sn_collecton.append(TP/(TP+FN))\n",
    "Sp_collecton.append(TN/(TN+FP))\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "MCC_collecton.append(MCC)\n",
    "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "from sklearn.metrics import roc_auc_score\n",
    "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
    "AUC_collecton.append(AUC)"
   ],
   "metadata": {
    "id": "KPwEv_WsnH6Q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ee2ab18-c562-4c87-870e-2b5ad8538e86",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:21:15.531481Z",
     "start_time": "2024-07-12T22:20:23.852161Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "64/64 - 5s - loss: 1.3020 - accuracy: 0.6490 - val_loss: 0.7436 - val_accuracy: 0.5000 - lr: 0.1000 - 5s/epoch - 81ms/step\n",
      "Epoch 2/200\n",
      "64/64 - 2s - loss: 0.5671 - accuracy: 0.7098 - val_loss: 0.7234 - val_accuracy: 0.5000 - lr: 0.1000 - 2s/epoch - 38ms/step\n",
      "Epoch 3/200\n",
      "64/64 - 2s - loss: 0.4892 - accuracy: 0.7843 - val_loss: 0.7524 - val_accuracy: 0.5000 - lr: 0.0600 - 2s/epoch - 36ms/step\n",
      "Epoch 4/200\n",
      "64/64 - 1s - loss: 0.4301 - accuracy: 0.8098 - val_loss: 0.7743 - val_accuracy: 0.5000 - lr: 0.0600 - 982ms/epoch - 15ms/step\n",
      "Epoch 5/200\n",
      "64/64 - 1s - loss: 0.3994 - accuracy: 0.8157 - val_loss: 0.7574 - val_accuracy: 0.5000 - lr: 0.0600 - 1s/epoch - 17ms/step\n",
      "Epoch 6/200\n",
      "64/64 - 1s - loss: 0.3726 - accuracy: 0.8118 - val_loss: 0.7089 - val_accuracy: 0.5652 - lr: 0.0360 - 1s/epoch - 19ms/step\n",
      "Epoch 7/200\n",
      "64/64 - 1s - loss: 0.3381 - accuracy: 0.8333 - val_loss: 0.7049 - val_accuracy: 0.5652 - lr: 0.0360 - 861ms/epoch - 13ms/step\n",
      "Epoch 8/200\n",
      "64/64 - 1s - loss: 0.3495 - accuracy: 0.8490 - val_loss: 0.7427 - val_accuracy: 0.5652 - lr: 0.0360 - 790ms/epoch - 12ms/step\n",
      "Epoch 9/200\n",
      "64/64 - 3s - loss: 0.2959 - accuracy: 0.8765 - val_loss: 0.7924 - val_accuracy: 0.6087 - lr: 0.0216 - 3s/epoch - 44ms/step\n",
      "Epoch 10/200\n",
      "64/64 - 1s - loss: 0.2726 - accuracy: 0.8902 - val_loss: 0.8956 - val_accuracy: 0.6413 - lr: 0.0216 - 1s/epoch - 21ms/step\n",
      "Epoch 11/200\n",
      "64/64 - 1s - loss: 0.2799 - accuracy: 0.8745 - val_loss: 1.0303 - val_accuracy: 0.6630 - lr: 0.0216 - 1s/epoch - 22ms/step\n",
      "Epoch 12/200\n",
      "64/64 - 1s - loss: 0.2594 - accuracy: 0.8902 - val_loss: 1.1720 - val_accuracy: 0.6196 - lr: 0.0130 - 831ms/epoch - 13ms/step\n",
      "Epoch 13/200\n",
      "64/64 - 1s - loss: 0.2460 - accuracy: 0.9098 - val_loss: 1.1375 - val_accuracy: 0.6304 - lr: 0.0130 - 875ms/epoch - 14ms/step\n",
      "Epoch 14/200\n",
      "64/64 - 1s - loss: 0.2450 - accuracy: 0.9059 - val_loss: 1.0745 - val_accuracy: 0.6304 - lr: 0.0130 - 753ms/epoch - 12ms/step\n",
      "Epoch 15/200\n",
      "64/64 - 1s - loss: 0.2171 - accuracy: 0.9176 - val_loss: 1.2178 - val_accuracy: 0.6087 - lr: 0.0078 - 763ms/epoch - 12ms/step\n",
      "Epoch 16/200\n",
      "64/64 - 1s - loss: 0.2278 - accuracy: 0.9039 - val_loss: 1.2275 - val_accuracy: 0.6304 - lr: 0.0078 - 807ms/epoch - 13ms/step\n",
      "Epoch 17/200\n",
      "64/64 - 1s - loss: 0.2065 - accuracy: 0.9255 - val_loss: 1.3272 - val_accuracy: 0.6522 - lr: 0.0078 - 737ms/epoch - 12ms/step\n",
      "Epoch 18/200\n",
      "64/64 - 1s - loss: 0.1914 - accuracy: 0.9216 - val_loss: 1.3345 - val_accuracy: 0.6522 - lr: 0.0047 - 707ms/epoch - 11ms/step\n",
      "Epoch 19/200\n",
      "64/64 - 1s - loss: 0.1870 - accuracy: 0.9196 - val_loss: 1.2914 - val_accuracy: 0.6522 - lr: 0.0047 - 758ms/epoch - 12ms/step\n",
      "Epoch 20/200\n",
      "64/64 - 1s - loss: 0.1919 - accuracy: 0.9255 - val_loss: 1.3075 - val_accuracy: 0.6413 - lr: 0.0047 - 771ms/epoch - 12ms/step\n",
      "Epoch 21/200\n",
      "64/64 - 1s - loss: 0.1952 - accuracy: 0.9216 - val_loss: 1.3060 - val_accuracy: 0.6413 - lr: 0.0028 - 847ms/epoch - 13ms/step\n",
      "Epoch 22/200\n",
      "64/64 - 1s - loss: 0.1899 - accuracy: 0.9275 - val_loss: 1.3262 - val_accuracy: 0.6522 - lr: 0.0028 - 767ms/epoch - 12ms/step\n",
      "Epoch 23/200\n",
      "64/64 - 1s - loss: 0.1752 - accuracy: 0.9471 - val_loss: 1.3117 - val_accuracy: 0.6413 - lr: 0.0028 - 670ms/epoch - 10ms/step\n",
      "Epoch 24/200\n",
      "64/64 - 1s - loss: 0.1652 - accuracy: 0.9451 - val_loss: 1.3485 - val_accuracy: 0.6413 - lr: 0.0017 - 683ms/epoch - 11ms/step\n",
      "Epoch 25/200\n",
      "64/64 - 1s - loss: 0.1695 - accuracy: 0.9314 - val_loss: 1.3736 - val_accuracy: 0.6413 - lr: 0.0017 - 708ms/epoch - 11ms/step\n",
      "Epoch 26/200\n",
      "64/64 - 1s - loss: 0.1630 - accuracy: 0.9471 - val_loss: 1.3879 - val_accuracy: 0.6413 - lr: 0.0017 - 690ms/epoch - 11ms/step\n",
      "Epoch 27/200\n",
      "64/64 - 1s - loss: 0.1834 - accuracy: 0.9294 - val_loss: 1.3802 - val_accuracy: 0.6413 - lr: 0.0010 - 697ms/epoch - 11ms/step\n",
      "Epoch 28/200\n",
      "64/64 - 1s - loss: 0.1734 - accuracy: 0.9431 - val_loss: 1.3757 - val_accuracy: 0.6413 - lr: 0.0010 - 679ms/epoch - 11ms/step\n",
      "Epoch 29/200\n",
      "64/64 - 1s - loss: 0.1685 - accuracy: 0.9314 - val_loss: 1.3776 - val_accuracy: 0.6413 - lr: 0.0010 - 667ms/epoch - 10ms/step\n",
      "Epoch 30/200\n",
      "64/64 - 1s - loss: 0.1681 - accuracy: 0.9412 - val_loss: 1.3779 - val_accuracy: 0.6413 - lr: 6.0466e-04 - 765ms/epoch - 12ms/step\n",
      "Epoch 31/200\n",
      "64/64 - 1s - loss: 0.1751 - accuracy: 0.9529 - val_loss: 1.3894 - val_accuracy: 0.6413 - lr: 6.0466e-04 - 753ms/epoch - 12ms/step\n",
      "Epoch 32/200\n",
      "64/64 - 1s - loss: 0.1590 - accuracy: 0.9471 - val_loss: 1.3920 - val_accuracy: 0.6413 - lr: 6.0466e-04 - 708ms/epoch - 11ms/step\n",
      "Epoch 33/200\n",
      "64/64 - 1s - loss: 0.1618 - accuracy: 0.9529 - val_loss: 1.3824 - val_accuracy: 0.6413 - lr: 3.6280e-04 - 755ms/epoch - 12ms/step\n",
      "Epoch 34/200\n",
      "64/64 - 1s - loss: 0.1600 - accuracy: 0.9490 - val_loss: 1.3898 - val_accuracy: 0.6413 - lr: 3.6280e-04 - 696ms/epoch - 11ms/step\n",
      "Epoch 35/200\n",
      "64/64 - 1s - loss: 0.1651 - accuracy: 0.9392 - val_loss: 1.4004 - val_accuracy: 0.6413 - lr: 3.6280e-04 - 714ms/epoch - 11ms/step\n",
      "Epoch 36/200\n",
      "64/64 - 1s - loss: 0.1796 - accuracy: 0.9294 - val_loss: 1.3994 - val_accuracy: 0.6413 - lr: 2.1768e-04 - 742ms/epoch - 12ms/step\n",
      "Epoch 37/200\n",
      "64/64 - 1s - loss: 0.1505 - accuracy: 0.9569 - val_loss: 1.4030 - val_accuracy: 0.6413 - lr: 2.1768e-04 - 692ms/epoch - 11ms/step\n",
      "Epoch 38/200\n",
      "64/64 - 1s - loss: 0.1633 - accuracy: 0.9392 - val_loss: 1.4116 - val_accuracy: 0.6413 - lr: 2.1768e-04 - 735ms/epoch - 11ms/step\n",
      "Epoch 39/200\n",
      "64/64 - 1s - loss: 0.1656 - accuracy: 0.9314 - val_loss: 1.4104 - val_accuracy: 0.6413 - lr: 1.3061e-04 - 697ms/epoch - 11ms/step\n",
      "Epoch 40/200\n",
      "64/64 - 1s - loss: 0.1632 - accuracy: 0.9392 - val_loss: 1.4062 - val_accuracy: 0.6413 - lr: 1.3061e-04 - 795ms/epoch - 12ms/step\n",
      "Epoch 41/200\n",
      "64/64 - 1s - loss: 0.1630 - accuracy: 0.9490 - val_loss: 1.4039 - val_accuracy: 0.6413 - lr: 1.3061e-04 - 730ms/epoch - 11ms/step\n",
      "Epoch 42/200\n",
      "64/64 - 1s - loss: 0.1684 - accuracy: 0.9471 - val_loss: 1.4033 - val_accuracy: 0.6413 - lr: 7.8364e-05 - 743ms/epoch - 12ms/step\n",
      "Epoch 43/200\n",
      "64/64 - 1s - loss: 0.1686 - accuracy: 0.9373 - val_loss: 1.4017 - val_accuracy: 0.6413 - lr: 7.8364e-05 - 704ms/epoch - 11ms/step\n",
      "Epoch 44/200\n",
      "64/64 - 1s - loss: 0.1589 - accuracy: 0.9431 - val_loss: 1.4001 - val_accuracy: 0.6413 - lr: 7.8364e-05 - 701ms/epoch - 11ms/step\n",
      "Epoch 45/200\n",
      "64/64 - 1s - loss: 0.1569 - accuracy: 0.9431 - val_loss: 1.3991 - val_accuracy: 0.6413 - lr: 4.7018e-05 - 705ms/epoch - 11ms/step\n",
      "Epoch 46/200\n",
      "64/64 - 1s - loss: 0.1502 - accuracy: 0.9529 - val_loss: 1.4023 - val_accuracy: 0.6413 - lr: 4.7018e-05 - 837ms/epoch - 13ms/step\n",
      "Epoch 47/200\n",
      "64/64 - 1s - loss: 0.1722 - accuracy: 0.9392 - val_loss: 1.4042 - val_accuracy: 0.6413 - lr: 4.7018e-05 - 724ms/epoch - 11ms/step\n",
      "Epoch 48/200\n",
      "64/64 - 1s - loss: 0.1610 - accuracy: 0.9431 - val_loss: 1.4048 - val_accuracy: 0.6413 - lr: 2.8211e-05 - 724ms/epoch - 11ms/step\n",
      "Epoch 49/200\n",
      "64/64 - 1s - loss: 0.1443 - accuracy: 0.9529 - val_loss: 1.4064 - val_accuracy: 0.6413 - lr: 2.8211e-05 - 738ms/epoch - 12ms/step\n",
      "Epoch 50/200\n",
      "64/64 - 1s - loss: 0.1630 - accuracy: 0.9373 - val_loss: 1.4045 - val_accuracy: 0.6413 - lr: 2.8211e-05 - 723ms/epoch - 11ms/step\n",
      "Epoch 51/200\n",
      "64/64 - 1s - loss: 0.1537 - accuracy: 0.9490 - val_loss: 1.4040 - val_accuracy: 0.6413 - lr: 1.6927e-05 - 676ms/epoch - 11ms/step\n",
      "92/92 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "print(ACC_collecton[0])\n",
    "print(BACC_collecton[0])\n",
    "print(Sn_collecton[0])\n",
    "print(Sp_collecton[0])\n",
    "print(MCC_collecton[0])\n",
    "print(AUC_collecton[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BF0RTvNSBcMl",
    "outputId": "476d3df8-c669-4156-ea10-dd2429cf0b29",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:21:15.548056Z",
     "start_time": "2024-07-12T22:21:15.532208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6630434782608695\n",
      "0.6888341543513957\n",
      "0.6190476190476191\n",
      "0.7586206896551724\n",
      "0.3509312031717982\n",
      "0.672022684310019\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "model.save('APP_tensorflow_model',save_format = 'tf') \n",
    "!zip -r /content/AMAP_alternative_tensorflow_model.zip /content/AMAP_alternative_tensorflow_model"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDNAw5DCUDHT",
    "outputId": "eafb3ce8-0db6-4f48-aecd-8d6377ac8893",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:21:19.374953Z",
     "start_time": "2024-07-12T22:21:15.548737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: APP_tensorflow_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: APP_tensorflow_model\\assets\n",
      "'zip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "### t-SNE graph making"
   ],
   "metadata": {
    "id": "1G1yUX0bCZyG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# loading datasset\n",
    "X_train_data_name = 'BBP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
    "X_test_data_name = 'BBP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
    "X_train = np.array(X_train_data)\n",
    "X_test = np.array(X_test_data)\n",
    "# training dataset loading\n",
    "dataset = pd.read_excel('BBP_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
    "# loading the y dataset for model development \n",
    "y_train = dataset['label']\n",
    "y_train = np.array(y_train) # transformed as np.array for CNN model\n",
    "# training dataset loading\n",
    "dataset = pd.read_excel('BBP_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
    "# loading the y dataset for model development \n",
    "y_test = dataset['label']\n",
    "y_test = np.array(y_test) # transformed as np.array for CNN model\n",
    "# normalize the X data range (just )\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
    "X_test = scaler.transform(X_test)\n",
    "# concatenate the dataset\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.datasets import mnist\n",
    "from sklearn.datasets import load_iris\n",
    "from numpy import reshape\n",
    "import seaborn as sns\n",
    "import pandas as pd  \n",
    "tsne = TSNE(n_components=2, verbose=0, perplexity= 25, learning_rate='auto',n_iter = 5000,random_state=123)\n",
    "z = tsne.fit_transform(X) \n",
    "df = pd.DataFrame()\n",
    "df[\"comp-1\"] = z[:,0]\n",
    "df[\"comp-2\"] = z[:,1]\n",
    "y_new_label=[]\n",
    "for i in y:\n",
    "    if i == 0:\n",
    "        y_new_label.append('Active')\n",
    "    if i == 1:\n",
    "        y_new_label.append('Inactive')\n",
    "df[\"y\"] = y_new_label\n",
    "graph = sns.scatterplot(data=df, x=\"comp-1\", y=\"comp-2\", hue=y_new_label,\n",
    "                palette='BrBG_r', legend='full')\n",
    "graph_for_output = graph.get_figure()\n",
    "graph_for_output.savefig('11.BBP_t-SNE.png', dpi=300)\n",
    "df.to_excel('11.BBP_t-SNE.xlsx')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "abadUCq3CeO3",
    "outputId": "67ea80d8-d380-4ddf-a827-d7cbaba87419",
    "ExecuteTime": {
     "end_time": "2024-07-12T22:21:21.566334Z",
     "start_time": "2024-07-12T22:21:19.377558Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BBP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# loading datasset\u001B[39;00m\n\u001B[0;32m      2\u001B[0m X_train_data_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBBP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 3\u001B[0m X_train_data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_data_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m X_test_data_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBBP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      5\u001B[0m X_test_data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(X_test_data_name,header\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, index_col \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,delimiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mc:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mc:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1664\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1670\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mc:\\users\\harel\\pycharmprojects\\unidl4biopep-auto\\venv\\lib\\site-packages\\pandas\\io\\common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    863\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'BBP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": "# !pip install umap",
   "metadata": {
    "id": "rQIWSlOUCwqb"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap\r\n",
      "  Downloading umap-0.1.1.tar.gz (3.2 kB)\r\n",
      "Building wheels for collected packages: umap\r\n",
      "  Building wheel for umap (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3564 sha256=879a7899406d5aec8c819a383fa99940a5800f1e54e2ee1231bd20f2b57ac85c\r\n",
      "  Stored in directory: /Users/zhenjiaodu/Library/Caches/pip/wheels/d4/13/91/2e752dc8dab5df027854bd33d2b65e1dc5cdc107fd1133990f\r\n",
      "Successfully built umap\r\n",
      "Installing collected packages: umap\r\n",
      "Successfully installed umap-0.1.1\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/jn/46mlt8753tq08psvz71pkvnr0000gn/T/ipykernel_86796/3494986884.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mumap\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mreducer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mumap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUMAP\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
